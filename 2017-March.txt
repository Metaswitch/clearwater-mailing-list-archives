From Sebastian.Rex at metaswitch.com  Wed Mar  1 04:31:02 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Wed, 1 Mar 2017 09:31:02 +0000
Subject: [Project Clearwater] Fwd: manually install clearwater on
 OpenStack - SIP error 408
In-Reply-To: <CAOJ1h8VoY0wxRnyANV0TH=7NJHRE4-ceTZkNaPPVqJBUnnMS9g@mail.gmail.com>
References: <CAOJ1h8W6g-9DNnLdY_=1ze4=MLnhiZVnWmAPrfKghzsSVjFWpw@mail.gmail.com>
	<CAOJ1h8VoY0wxRnyANV0TH=7NJHRE4-ceTZkNaPPVqJBUnnMS9g@mail.gmail.com>
Message-ID: <SN1PR02MB16643368178281492A60A5E38F290@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

It looks like you?re getting a 200 OK to the REGISTER request, but you?re getting a 408 to a subsequent SUBSCRIBE request (you can see this in the packet capture you attached). So the client should be registered correctly. Are calls working?

The SUBSCRIBE message appears to be for:


?application/simple-message-summary?



which is used for message waiting indication. If you don?t expect to be using MWI, then you should turn off the SUBSCRIBE in X-Lite. If memory serves, there?s a ?Voicemail? tab in the X-Lite Account Settings which you can use to turn this off.



All that we can see from the snippet of sprout logs that you included is that the OPTIONS poll succeeds (this is sprout?s health-checking poll).



Hope that helps,

Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Xiaobai Li
Sent: 28 February 2017 23:34
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] Fwd: manually install clearwater on OpenStack - SIP error 408

Hi guys,

I wrote an email before to ask an 408 error when registering manually installed clearwater through X-Lite. Currently, when I am trying to register, it will directly give me an 408 time out error. Here I attached the log information on sprout. Hope anyone who could help me to figure out what's going on.

The log information on sprout node as follows.

Thanks a lot!

--start msg--

OPTIONS sip:poll-sip at 172.27.1.21:5054<http://sip:poll-sip at 172.27.1.21:5054/> SIP/2.0
Via: SIP/2.0/TCP 172.27.1.21;rport;branch=z9hG4bK-4490
Max-Forwards: 2
To: <sip:poll-sip at 172.27.1.21:5054<http://sip:poll-sip at 172.27.1.21:5054/>>
From: poll-sip <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=4490
Call-ID: poll-sip-4490
CSeq: 4490 OPTIONS
Contact: <sip:172.27.1.21>
Accept: application/sdp
Content-Length: 0
User-Agent: poll-sip
^M

--end msg--
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI as 3
28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:213: Skipping SAS logging for OPTIONS request
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:264: Queuing cloned received message 0x7fab0800d108 for worker threads
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:150: Worker thread dequeue message 0x7fab0800d108
28-02-2017 23:26:34.660 UTC Debug pjsip: sip_endpoint.c Distributing rdata to modules: Request msg OPTIONS/cseq=4490 (rdata0x7fab0800d108)
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI as 3
28-02-2017 23:26:34.660 UTC Debug pjsip:       endpoint Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) created
28-02-2017 23:26:34.660 UTC Verbose common_sip_processing.cpp:136: TX 268 bytes Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) to TCP 172.27.1.21:53896<http://172.27.1.21:53896/>:
--start msg--

SIP/2.0 200 OK^M
Via: SIP/2.0/TCP 172.27.1.21;rport=53896;received=172.27.1.21;branch=z9hG4bK-4490^M
Call-ID: poll-sip-4490^M
From: "poll-sip" <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=4490^M
To: <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=z9hG4bK-4490^M
CSeq: 4490 OPTIONS^M
Content-Length:  0^M
^M

--end msg--
28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:262: Skipping SAS logging for OPTIONS response
28-02-2017 23:26:34.660 UTC Debug pjsip: tdta0x7fab1400 Destroying txdata Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50)
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:200: Worker thread completed processing message 0x7fab0800d108
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:206: Request latency = 125us
28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:342: Process request for URL /ping, args (null)
28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:90: Sending response 200 to request for URL /ping, args (null)
28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP connection closed
28-02-2017 23:26:36.662 UTC Status connection_tracker.cpp:92: Connection 0x7fab0800a428 has been destroyed
28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP transport destroyed with reason 70016: End of file (PJ_EEOF)

---------- Forwarded message ----------
From: Xiaobai Li <leeshirley2002 at gmail.com<mailto:leeshirley2002 at gmail.com>>
Date: 2017-02-06 20:15 GMT-08:00
Subject: manually install clearwater on OpenStack - SIP error 408
To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>

Hi guys,

I followed the manual installation instructions and successfully installed clearwater on Openstack using 7 vms (1 private DNS zone). I used the SIP client X-lite and successfully registered a user. However, sometimes the X-lite gives me a SIP error 408 and I couldn't make calls between registered users.
Here is my settings for the X-lite:
General:

User ID: 6505550631<tel:(650)%20555-0631>
Domain: ims.hom
password: *******
Display name: **
Authorization name: 6505550631<tel:(650)%20555-0631>@ims.hom

Domain Proxy:
Send outbound via:
proxy: {bono ip address}

Topology:
sever address: ims.hom
Username: 6505550631<tel:(650)%20555-0631>@ims.hom
password: ******


Here I also attached the tcpdump between bono and my SIP client when registering a user, after 200 for registration it gives me 408 error for subscribe.

Hope anyone can help me to figure out this problem. Thanks a lot!

Shirley




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170301/531f6a04/attachment.html>

From Sebastian.Rex at metaswitch.com  Wed Mar  1 04:40:37 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Wed, 1 Mar 2017 09:40:37 +0000
Subject: [Project Clearwater] Throttling effect in sprout
In-Reply-To: <SIXPR04MB0778427BABD4CC0F12816184E0570@SIXPR04MB0778.apcprd04.prod.outlook.com>
References: <SIXPR04MB0778427BABD4CC0F12816184E0570@SIXPR04MB0778.apcprd04.prod.outlook.com>
Message-ID: <SN1PR02MB1664581580F7AC4F6AB2CB9D8F290@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

The overload point of a single sprout node will depend on the size of the node, amongst other factors, and so we don't provide a predefined overload point. 50 calls/second is probably quite close to the limit already for a single CPU sprout node.

As a general rule, if you want to see whether a sprout node is overloaded, the most reliable measure is probably CPU usage on the node.

As for your comments regarding tokens: if you think that the tokens are limiting the number of calls you can make, then you should be able to see this fairly easily because any SIP messages which cannot be handled by Sprout (due to not having any tokens available) will receive a 503 response. Also, you will see "Status" logs from the load_monitor in /var/log/sprout/sprout_current.txt which will tell you the state of the load monitor periodically. If the token rate is the limiting factor, then you could either adjust the token settings (as per below) or you could just ramp up the call load more slowly (i.e. rather than going from 0 calls/second to 100 immediately, you slowly increase the call rate from 0 to 100 to allow Sprout to adjust the token values).

For your specific questions:


1)      You can't disable dynamic throttling using configuration options. However, you can increase the initial maximum number of tokens as well as the token fill rate. To do this, use the options listed here: http://clearwater.readthedocs.io/en/latest/Clearwater_Configuration_Options_Reference.html, specifically the "max_tokens" and "init_token_rate". Increasing the size of these will increase the number of tokens available, and hence make throttling happen later.


2)      No, there's no predefined overload point.



3)      The recommended settings would depend on your deployment. If you're trying to stress Sprout specifically, then you may have issues if you're directing your SIP traffic through the Bono node (which our older stress scripts do). We don't believe that Bono scales as well as Sprout and may well bottle-neck first, and so when performing stress testing we advise that you should either stress test the IMS core directly (by using the new-style stress scripts as documented here: http://clearwater.readthedocs.io/en/latest/Clearwater_stress_testing.html?#sip-stress-nodes) or you should use a carrier-grade P-CSCF as recommended for production deployments (such as Metaswitch Perimeta)



4)      As above, if your stress testing is going through Bono then it may well be the bottle-neck here. Also, depending on your load profile and size of your VMs, Homestead could also be a bottle-neck. If you think that homestead might be limiting the load that Sprout can handle, then you should use more (or more powerful) Homestead nodes to ensure that Homestead's not the bottle-neck. You should be able to see if Sprout is the bottle-neck by looking at the CPU usage on your Sprout nodes.



5)      If you've ensured that Sprout is the bottle-neck in your deployment, then scaling out Sprout alone should be enough (each node type can be scaled our independently of the others).


I hope that helps,

Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of JACKSON JULIET ROY
Sent: 27 February 2017 07:56
To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>
Subject: [Project Clearwater] Throttling effect in sprout

Dear All,

We are trying to evaluate the performance of single sprout node against two sprout nodes in the Clearwater IMS for the SIP call load. (using multi VM based CW IMS image) This is to demonstrate the necessity and advantage of scaling out the sprout node.

So what we are attempting is to find out the overload point of single sprout when calls start failing, whereas for the similar load two sprout scenario works fine. We use SIPp to emulate calls. We normally generate from 50 calls/sec and keep in increasing till 100/150 calls per second.

However when we are experimenting the above scenario (first to find the overload point for single sprout), we  are finding inconsistent observation. Some time single sprout creates call failures for even 50 calls/ sec, but if we experiment after sometime single sprout is able to tolerate even more than 100 calls per seconds. Based on our study from CW website, we understand that this might be due to  dynamic throttling supported  by CW IMS nodes.  We have tried to manipulate the value of max tokens as well as the token rate to ensure there is no dynamic throttling, however couldn't find any visible improvement in the observation. Due to this we are unable to fix the overload point for single sprout hence couldn't able to do a testing for getting visible performance improvement comparison between single and two sprout nodes.

I have few queries here. Can you please help us in getting clarity here?


1)      Is there a possibility exist to disable dynamic throttling? If not, any parameter setting e.g. token related parameter will ensure throttling is not happening?

2)      Is there a predefined overload point in terms of number SIP calls/ sec for a single sprout? (we are suing single single core, 2 GB RAM, 20 GB hard disk VM for sprout)

3)      Is there any recommended parameters for this kind of testing -  in terms of SIP load ie calls/sec. any configuration parameter setting (like token as well as any other)?

4)      As per our understanding sprout is first component expected to be scaled out because it will be more loaded than any other CW IMS nodes. Is our understanding is correct?

5)      When we scale out sprout, scaling out sprout alone is enough or any other nodes also expected to be scaled out to see the performance improvement?

Thanks,
Jackson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170301/9942cb50/attachment.html>

From leeshirley2002 at gmail.com  Wed Mar  1 17:23:55 2017
From: leeshirley2002 at gmail.com (Xiaobai Li)
Date: Wed, 1 Mar 2017 14:23:55 -0800
Subject: [Project Clearwater] Fwd: manually install clearwater on
 OpenStack - SIP error 408
In-Reply-To: <SN1PR02MB16643368178281492A60A5E38F290@SN1PR02MB1664.namprd02.prod.outlook.com>
References: <CAOJ1h8W6g-9DNnLdY_=1ze4=MLnhiZVnWmAPrfKghzsSVjFWpw@mail.gmail.com>
	<CAOJ1h8VoY0wxRnyANV0TH=7NJHRE4-ceTZkNaPPVqJBUnnMS9g@mail.gmail.com>
	<SN1PR02MB16643368178281492A60A5E38F290@SN1PR02MB1664.namprd02.prod.outlook.com>
Message-ID: <CAOJ1h8VJ2_3zR1-xVy5hGwSojkegbpsU-TED_eeZkZfbjNGraQ@mail.gmail.com>

Hi Seb,

Thanks a lot for your reply. Actually, currently I directly got 408 from
Bono node for REGISTER request. Here is the current packet capture from
Bono. It seems like after X-Lite sends a REGISTER request to Bono, the Bono
gave me a 408 error. The Bono didn't send the REGISTER request to Sprout.
The only thing that I changed is the DNS server reverse zone configuration.
Hope I could receive some suggestions from your side.

Thanks!

10.145.15.10.57729 > bono.sip: Flags [P.], cksum 0x46e9 (correct), seq
1115:1671, ack 755, win 32768, length 556

        0x0000:  fa16 3e09 2d9d fa16 3ecc 35dc 0800 4500  ..>.-...>.5...E.

        0x0010:  0254 9dce 0000 3d06 170c 0a91 0f0a ac1b  .T....=.........

        0x0020:  0114 e181 13c4 4fab 5f38 386f 3984 5018  ......O._88o9.P.

        0x0030:  8000 46e9 0000 5245 4749 5354 4552 2073  ..F...REGISTER.s

        0x0040:  6970 3a69 6d73 2e68 6f6d 2053 4950 2f32  ip:ims.hom.SIP/2

        0x0050:  2e30 0d0a 5669 613a 2053 4950 2f32 2e30  .0..Via:.SIP/2.0

        0x0060:  2f54 4350 2031 302e 3134 352e 3135 2e31  /TCP.10.145.15.1

        0x0070:  303a 3537 3732 383b 6272 616e 6368 3d7a  0:57728;branch=z

        0x0080:  3968 4734 624b 2d35 3234 3238 372d 312d  9hG4bK-524287-1-

        0x0090:  2d2d 3065 6137 3165 3164 3332 6336 6633  --0ea71e1d32c6f3

        0x00a0:  3266 3b72 706f 7274 0d0a 4d61 782d 466f  2f;rport..Max-Fo

        0x00b0:  7277 6172 6473 3a20 3730 0d0a 436f 6e74  rwards:.70..Cont

        0x00c0:  6163 743a 203c 7369 703a 3635 3035 3535  act:.<sip:650555

        0x00d0:  3039 3234 4031 302e 3134 352e 3135 2e31  0924 at 10.145.15.1

        0x00e0:  303a 3537 3732 383b 7269 6e73 7461 6e63  0:57728;rinstanc

        0x00f0:  653d 3362 6534 3461 6138 6463 3439 3466  e=3be44aa8dc494f

        0x0100:  3764 3b74 7261 6e73 706f 7274 3d74 6370  7d;transport=tcp

        0x0110:  3e0d 0a54 6f3a 2022 5869 616f 6261 6922  >..To:."Xiaobai"

        0x0120:  3c73 6970 3a36 3530 3535 3530 3932 3440  <sip:6505550924@

        0x0130:  696d 732e 686f 6d3e 0d0a 4672 6f6d 3a20  ims.hom>..From:.

        0x0140:  2258 6961 6f62 6169 223c 7369 703a 3635  "Xiaobai"<sip:65

        0x0150:  3035 3535 3039 3234 4069 6d73 2e68 6f6d  05550924 at ims.hom

        0x0160:  3e3b 7461 673d 3638 6636 3239 3431 0d0a  >;tag=68f62941..

        0x0170:  4361 6c6c 2d49 443a 2038 3231 3538 5a6a  Call-ID:.82158Zj

        0x0180:  526a 4f44 6330 4e7a 5a69 4e6d 526a 4f54  RjODc0NzZiNmRjOT

        0x0190:  5a6b 5932 457a 4e7a 5931 4d6a 6730 4e44  ZkY2EzNzY1Mjg0ND

        0x01a0:  4933 5a47 5933 4e6a 4d0d 0a43 5365 713a  I3ZGY3NjM..CSeq:

        0x01b0:  2033 2052 4547 4953 5445 520d 0a45 7870  .3.REGISTER..Exp

        0x01c0:  6972 6573 3a20 3336 3030 0d0a 416c 6c6f  ires:.3600..Allo

        0x01d0:  773a 2053 5542 5343 5249 4245 2c20 4e4f  w:.SUBSCRIBE,.NO

        0x01e0:  5449 4659 2c20 494e 5649 5445 2c20 4143  TIFY,.INVITE,.AC

        0x01f0:  4b2c 2043 414e 4345 4c2c 2042 5945 2c20  K,.CANCEL,.BYE,.

        0x0200:  5245 4645 522c 2049 4e46 4f2c 204f 5054  REFER,.INFO,.OPT

        0x0210:  494f 4e53 2c20 4d45 5353 4147 450d 0a55  IONS,.MESSAGE..U

        0x0220:  7365 722d 4167 656e 743a 2058 2d4c 6974  ser-Agent:.X-Lit

        0x0230:  6520 7265 6c65 6173 6520 342e 392e 3620  e.release.4.9.6.

        0x0240:  7374 616d 7020 3832 3135 380d 0a43 6f6e  stamp.82158..Con

        0x0250:  7465 6e74 2d4c 656e 6774 683a 2030 0d0a  tent-Length:.0..

        0x0260:  0d0a                                     ..

22:09:54.805344 IP (tos 0x0, ttl 64, id 15286, offset 0, flags [DF], proto
TCP (6), length 417)

    bono.sip > 10.145.15.10.57729: Flags [P.], cksum 0xc85d (incorrect ->
0x771f), seq 755:1132, ack 1671, win 31136, length 377

        0x0000:  fa16 3ecc 35dc fa16 3e09 2d9d 0800 4500  ..>.5...>.-...E.

        0x0010:  01a1 3bb6 4000 4006 36d7 ac1b 0114 0a91  ..;. at .@.6.......

        0x0020:  0f0a 13c4 e181 386f 3984 4fab 6164 5018  ......8o9.O.adP.

        0x0030:  79a0 c85d 0000 5349 502f 322e 3020 3430  y..]..SIP/2.0.40

        0x0040:  3820 5265 7175 6573 7420 5469 6d65 6f75  8.Request.Timeou

        0x0050:  740d 0a56 6961 3a20 5349 502f 322e 302f  t..Via:.SIP/2.0/

        0x0060:  5443 5020 3130 2e31 3435 2e31 352e 3130  TCP.10.145.15.10

        0x0070:  3a35 3737 3238 3b72 706f 7274 3d35 3737  :57728;rport=577

        0x0080:  3239 3b72 6563 6569 7665 643d 3130 2e31  29;received=10.1

        0x0090:  3435 2e31 352e 3130 3b62 7261 6e63 683d  45.15.10;branch=

        0x00a0:  7a39 6847 3462 4b2d 3532 3432 3837 2d31  z9hG4bK-524287-1

        0x00b0:  2d2d 2d30 6561 3731 6531 6433 3263 3666  ---0ea71e1d32c6f

        0x00c0:  3332 660d 0a43 616c 6c2d 4944 3a20 3832  32f..Call-ID:.82

        0x00d0:  3135 385a 6a52 6a4f 4463 304e 7a5a 694e  158ZjRjODc0NzZiN

        0x00e0:  6d52 6a4f 545a 6b59 3245 7a4e 7a59 314d  mRjOTZkY2EzNzY1M

        0x00f0:  6a67 304e 4449 335a 4759 334e 6a4d 0d0a  jg0NDI3ZGY3NjM..

        0x0100:  4672 6f6d 3a20 2258 6961 6f62 6169 2220  From:."Xiaobai".

        0x0110:  3c73 6970 3a36 3530 3535 3530 3932 3440  <sip:6505550924@

        0x0120:  696d 732e 686f 6d3e 3b74 6167 3d36 3866  ims.hom>;tag=68f

        0x0130:  3632 3934 310d 0a54 6f3a 2022 5869 616f  62941..To:."Xiao

        0x0140:  6261 6922 203c 7369 703a 3635 3035 3535  bai".<sip:650555

        0x0150:  3039 3234 4069 6d73 2e68 6f6d 3e3b 7461  0924 at ims.hom>;ta

        0x0160:  673d 7a39 6847 3462 4b2d 3532 3432 3837  g=z9hG4bK-524287

        0x0170:  2d31 2d2d 2d30 6561 3731 6531 6433 3263  -1---0ea71e1d32c

        0x0180:  3666 3332 660d 0a43 5365 713a 2033 2052  6f32f..CSeq:.3.R

        0x0190:  4547 4953 5445 520d 0a43 6f6e 7465 6e74  EGISTER..Content

        0x01a0:  2d4c 656e 6774 683a 2020 300d 0a0d 0a    -Length:..0....

22:09:54.807608 IP (tos 0x0, ttl 61, id 40399, offset 0, flags [none],
proto TCP (6), length 40)





2017-03-01 1:31 GMT-08:00 Sebastian Rex <Sebastian.Rex at metaswitch.com>:

> Hi,
>
>
>
> It looks like you?re getting a 200 OK to the REGISTER request, but you?re
> getting a 408 to a subsequent SUBSCRIBE request (you can see this in the
> packet capture you attached). So the client should be registered correctly.
> Are calls working?
>
>
>
> The SUBSCRIBE message appears to be for:
>
>
>
> ?application/simple-message-summary?
>
>
>
> which is used for message waiting indication. If you don?t expect to be using MWI, then you should turn off the SUBSCRIBE in X-Lite. If memory serves, there?s a ?Voicemail? tab in the X-Lite Account Settings which you can use to turn this off.
>
>
>
> All that we can see from the snippet of sprout logs that you included is that the OPTIONS poll succeeds (this is sprout?s health-checking poll).
>
>
>
> Hope that helps,
>
> Seb.
>
>
>
> *From:* Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org]
> *On Behalf Of *Xiaobai Li
> *Sent:* 28 February 2017 23:34
> *To:* clearwater at lists.projectclearwater.org
> *Subject:* [Project Clearwater] Fwd: manually install clearwater on
> OpenStack - SIP error 408
>
>
>
> Hi guys,
>
>
>
> I wrote an email before to ask an 408 error when registering manually
> installed clearwater through X-Lite. Currently, when I am trying to
> register, it will directly give me an 408 time out error. Here I attached
> the log information on sprout. Hope anyone who could help me to figure out
> what's going on.
>
>
>
> The log information on sprout node as follows.
>
>
>
> Thanks a lot!
>
>
>
> --start msg--
>
>
>
> OPTIONS sip:poll-sip at 172.27.1.21:5054 SIP/2.0
>
> Via: SIP/2.0/TCP 172.27.1.21;rport;branch=z9hG4bK-4490
>
> Max-Forwards: 2
>
> To: <sip:poll-sip at 172.27.1.21:5054>
>
> From: poll-sip <sip:poll-sip at 172.27.1.21>;tag=4490
>
> Call-ID: poll-sip-4490
>
> CSeq: 4490 OPTIONS
>
> Contact: <sip:172.27.1.21>
>
> Accept: application/sdp
>
> Content-Length: 0
>
> User-Agent: poll-sip
>
> ^M
>
>
>
> --end msg--
>
> 28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain:
> false, local_to_node: true, is_gruu: false, enforce_user_phone: false,
> prefer_sip: true, treat_number_as_phone: false
>
> 28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI
> as 3
>
> 28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:213: Skipping
> SAS logging for OPTIONS request
>
> 28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:264: Queuing
> cloned received message 0x7fab0800d108 for worker threads
>
> 28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:150: Worker thread
> dequeue message 0x7fab0800d108
>
> 28-02-2017 23:26:34.660 UTC Debug pjsip: sip_endpoint.c Distributing rdata
> to modules: Request msg OPTIONS/cseq=4490 (rdata0x7fab0800d108)
>
> 28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain:
> false, local_to_node: true, is_gruu: false, enforce_user_phone: false,
> prefer_sip: true, treat_number_as_phone: false
>
> 28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI
> as 3
>
> 28-02-2017 23:26:34.660 UTC Debug pjsip:       endpoint Response msg
> 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) created
>
> 28-02-2017 23:26:34.660 UTC Verbose common_sip_processing.cpp:136: TX 268
> bytes Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) to TCP
> 172.27.1.21:53896:
>
> --start msg--
>
>
>
> SIP/2.0 200 OK^M
>
> Via: SIP/2.0/TCP 172.27.1.21;rport=53896;received=172.27.1.21;branch=
> z9hG4bK-4490^M
>
> Call-ID: poll-sip-4490^M
>
> From: "poll-sip" <sip:poll-sip at 172.27.1.21>;tag=4490^M
>
> To: <sip:poll-sip at 172.27.1.21>;tag=z9hG4bK-4490^M
>
> CSeq: 4490 OPTIONS^M
>
> Content-Length:  0^M
>
> ^M
>
>
>
> --end msg--
>
> 28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:262: Skipping
> SAS logging for OPTIONS response
>
> 28-02-2017 23:26:34.660 UTC Debug pjsip: tdta0x7fab1400 Destroying txdata
> Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50)
>
> 28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:200: Worker thread
> completed processing message 0x7fab0800d108
>
> 28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:206: Request
> latency = 125us
>
> 28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:342: Process request for
> URL /ping, args (null)
>
> 28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:90: Sending response 200
> to request for URL /ping, args (null)
>
> 28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP connection
> closed
>
> 28-02-2017 23:26:36.662 UTC Status connection_tracker.cpp:92: Connection
> 0x7fab0800a428 has been destroyed
>
> 28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP transport
> destroyed with reason 70016: End of file (PJ_EEOF)
>
>
>
> ---------- Forwarded message ----------
> From: *Xiaobai Li* <leeshirley2002 at gmail.com>
> Date: 2017-02-06 20:15 GMT-08:00
> Subject: manually install clearwater on OpenStack - SIP error 408
> To: clearwater at lists.projectclearwater.org
>
> Hi guys,
>
>
>
> I followed the manual installation instructions and successfully installed
> clearwater on Openstack using 7 vms (1 private DNS zone). I used the SIP
> client X-lite and successfully registered a user. However, sometimes the
> X-lite gives me a SIP error 408 and I couldn't make calls between
> registered users.
>
> Here is my settings for the X-lite:
>
> General:
>
>
>
> User ID: 6505550631 <(650)%20555-0631>
>
> Domain: ims.hom
>
> password: *******
>
> Display name: **
>
> Authorization name: 6505550631 <(650)%20555-0631>@ims.hom
>
>
>
> Domain Proxy:
>
> Send outbound via:
>
> proxy: {bono ip address}
>
>
>
> Topology:
>
> sever address: ims.hom
>
> Username: 6505550631 <(650)%20555-0631>@ims.hom
>
> password: ******
>
>
>
>
>
> Here I also attached the tcpdump between bono and my SIP client when
> registering a user, after 200 for registration it gives me 408 error for
> subscribe.
>
>
>
> Hope anyone can help me to figure out this problem. Thanks a lot!
>
>
>
> Shirley
>
>
>
>
>
>
>
>
>
> _______________________________________________
> Clearwater mailing list
> Clearwater at lists.projectclearwater.org
> http://lists.projectclearwater.org/mailman/listinfo/clearwater_lists.
> projectclearwater.org
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170301/4eb44cc9/attachment.html>

From jake at dccllc.net  Wed Mar  1 23:08:21 2017
From: jake at dccllc.net (Jake Brown)
Date: Thu, 2 Mar 2017 04:08:21 +0000
Subject: [Project Clearwater] Sprout and third-party registrations
Message-ID: <CY4PR18MB1336E629976705422483350CA9280@CY4PR18MB1336.namprd18.prod.outlook.com>

I am looking for a IFC example that would induce the behavior described in the manual where the S-CSCF would pass a third party registration onto an AS:

>From the online manual:

AS invocation also occurs on REGISTER - this is called third-party registration (3GPP TS 24.229 s5.4.1.7 and 7A):

  *   When a UE registers with Sprout, if the iFCs require it, it passes a third-party registration onto an AS.
  *   Message body handling for third-party registration, per 3GPP TS 24.229 s5.4.1.7A: including optionally service info, a copy of the registration, and a copy of the response.
  *   Network-initiated deregister. If the third-party registration fails and the iFC requests it, we must deregister the UE.

Thank You

Jake
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170302/2336c0d8/attachment.html>

From jacky at tataelxsi.co.in  Fri Mar  3 01:19:24 2017
From: jacky at tataelxsi.co.in (JACKSON JULIET ROY)
Date: Fri, 3 Mar 2017 06:19:24 +0000
Subject: [Project Clearwater] Throttling effect in sprout
Message-ID: <SIXPR04MB0778C2CC8DC4271C97C8650BE02B0@SIXPR04MB0778.apcprd04.prod.outlook.com>

Hi Clearwater team,

Can you please respond for the below query which I have posted on 27th Monday?

Thanks,
Jackson

From: JACKSON JULIET ROY
Sent: 27 February 2017 13:26
To: 'clearwater at lists.projectclearwater.org' <clearwater at lists.projectclearwater.org>
Subject: Throttling effect in sprout

Dear All,

We are trying to evaluate the performance of single sprout node against two sprout nodes in the Clearwater IMS for the SIP call load. (using multi VM based CW IMS image) This is to demonstrate the necessity and advantage of scaling out the sprout node.

So what we are attempting is to find out the overload point of single sprout when calls start failing, whereas for the similar load two sprout scenario works fine. We use SIPp to emulate calls. We normally generate from 50 calls/sec and keep in increasing till 100/150 calls per second.

However when we are experimenting the above scenario (first to find the overload point for single sprout), we  are finding inconsistent observation. Some time single sprout creates call failures for even 50 calls/ sec, but if we experiment after sometime single sprout is able to tolerate even more than 100 calls per seconds. Based on our study from CW website, we understand that this might be due to  dynamic throttling supported  by CW IMS nodes.  We have tried to manipulate the value of max tokens as well as the token rate to ensure there is no dynamic throttling, however couldn't find any visible improvement in the observation. Due to this we are unable to fix the overload point for single sprout hence couldn't able to do a testing for getting visible performance improvement comparison between single and two sprout nodes.

I have few queries here. Can you please help us in getting clarity here?


1)      Is there a possibility exist to disable dynamic throttling? If not, any parameter setting e.g. token related parameter will ensure throttling is not happening?

2)      Is there a predefined overload point in terms of number SIP calls/ sec for a single sprout? (we are suing single single core, 2 GB RAM, 20 GB hard disk VM for sprout)

3)      Is there any recommended parameters for this kind of testing -  in terms of SIP load ie calls/sec. any configuration parameter setting (like token as well as any other)?

4)      As per our understanding sprout is first component expected to be scaled out because it will be more loaded than any other CW IMS nodes. Is our understanding is correct?

5)      When we scale out sprout, scaling out sprout alone is enough or any other nodes also expected to be scaled out to see the performance improvement?

Thanks,
Jackson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170303/de98e3d5/attachment.html>

From Sebastian.Rex at metaswitch.com  Fri Mar  3 04:49:31 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Fri, 3 Mar 2017 09:49:31 +0000
Subject: [Project Clearwater] Throttling effect in sprout
In-Reply-To: <SIXPR04MB0778C2CC8DC4271C97C8650BE02B0@SIXPR04MB0778.apcprd04.prod.outlook.com>
References: <SIXPR04MB0778C2CC8DC4271C97C8650BE02B0@SIXPR04MB0778.apcprd04.prod.outlook.com>
Message-ID: <SN1PR02MB1664AC59E34146E21AEBEB0F8F2B0@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

Are you not signed up to the mailing list? I've attached the response from Wednesday, but that was sent to the mailing list so if you're not signed up then you probably won't have seen it.

In order to ensure you see future responses, I'd recommend signing up by clicking the "Mailing List Signup" link from here: http://www.projectclearwater.org/community/

Thanks,
Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of JACKSON JULIET ROY
Sent: 03 March 2017 06:19
To: clearwater at lists.projectclearwater.org
Subject: Re: [Project Clearwater] Throttling effect in sprout

Hi Clearwater team,

Can you please respond for the below query which I have posted on 27th Monday?

Thanks,
Jackson

From: JACKSON JULIET ROY
Sent: 27 February 2017 13:26
To: 'clearwater at lists.projectclearwater.org' <clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>>
Subject: Throttling effect in sprout

Dear All,

We are trying to evaluate the performance of single sprout node against two sprout nodes in the Clearwater IMS for the SIP call load. (using multi VM based CW IMS image) This is to demonstrate the necessity and advantage of scaling out the sprout node.

So what we are attempting is to find out the overload point of single sprout when calls start failing, whereas for the similar load two sprout scenario works fine. We use SIPp to emulate calls. We normally generate from 50 calls/sec and keep in increasing till 100/150 calls per second.

However when we are experimenting the above scenario (first to find the overload point for single sprout), we  are finding inconsistent observation. Some time single sprout creates call failures for even 50 calls/ sec, but if we experiment after sometime single sprout is able to tolerate even more than 100 calls per seconds. Based on our study from CW website, we understand that this might be due to  dynamic throttling supported  by CW IMS nodes.  We have tried to manipulate the value of max tokens as well as the token rate to ensure there is no dynamic throttling, however couldn't find any visible improvement in the observation. Due to this we are unable to fix the overload point for single sprout hence couldn't able to do a testing for getting visible performance improvement comparison between single and two sprout nodes.

I have few queries here. Can you please help us in getting clarity here?


1)      Is there a possibility exist to disable dynamic throttling? If not, any parameter setting e.g. token related parameter will ensure throttling is not happening?

2)      Is there a predefined overload point in terms of number SIP calls/ sec for a single sprout? (we are suing single single core, 2 GB RAM, 20 GB hard disk VM for sprout)

3)      Is there any recommended parameters for this kind of testing -  in terms of SIP load ie calls/sec. any configuration parameter setting (like token as well as any other)?

4)      As per our understanding sprout is first component expected to be scaled out because it will be more loaded than any other CW IMS nodes. Is our understanding is correct?

5)      When we scale out sprout, scaling out sprout alone is enough or any other nodes also expected to be scaled out to see the performance improvement?

Thanks,
Jackson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170303/b1e90212/attachment.html>
-------------- next part --------------
An embedded message was scrubbed...
From: Sebastian Rex <Sebastian.Rex at metaswitch.com>
Subject: RE: Throttling effect in sprout
Date: Wed, 1 Mar 2017 09:40:37 +0000
Size: 23357
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170303/b1e90212/attachment.mht>

From jacky at tataelxsi.co.in  Fri Mar  3 08:17:07 2017
From: jacky at tataelxsi.co.in (JACKSON JULIET ROY)
Date: Fri, 3 Mar 2017 13:17:07 +0000
Subject: [Project Clearwater] Throttling effect in sprout
In-Reply-To: <SN1PR02MB1664AC59E34146E21AEBEB0F8F2B0@SN1PR02MB1664.namprd02.prod.outlook.com>
References: <SIXPR04MB0778C2CC8DC4271C97C8650BE02B0@SIXPR04MB0778.apcprd04.prod.outlook.com>
	<SN1PR02MB1664AC59E34146E21AEBEB0F8F2B0@SN1PR02MB1664.namprd02.prod.outlook.com>
Message-ID: <SIXPR04MB0778D17A7E1139B207228095E02B0@SIXPR04MB0778.apcprd04.prod.outlook.com>

Hi Seb,

Thanks for your response. Yes, I was not part of mailing list, now joined.

I will consider your suggestion during our testing. Will get back if any further clarity required.

Thanks,
Jackson

From: Sebastian Rex [mailto:Sebastian.Rex at metaswitch.com]
Sent: 03 March 2017 15:20
To: JACKSON JULIET ROY <jacky at tataelxsi.co.in>
Cc: clearwater at lists.projectclearwater.org
Subject: RE: Throttling effect in sprout

Hi,

Are you not signed up to the mailing list? I've attached the response from Wednesday, but that was sent to the mailing list so if you're not signed up then you probably won't have seen it.

In order to ensure you see future responses, I'd recommend signing up by clicking the "Mailing List Signup" link from here: http://www.projectclearwater.org/community/

Thanks,
Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of JACKSON JULIET ROY
Sent: 03 March 2017 06:19
To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>
Subject: Re: [Project Clearwater] Throttling effect in sprout

Hi Clearwater team,

Can you please respond for the below query which I have posted on 27th Monday?

Thanks,
Jackson

From: JACKSON JULIET ROY
Sent: 27 February 2017 13:26
To: 'clearwater at lists.projectclearwater.org' <clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>>
Subject: Throttling effect in sprout

Dear All,

We are trying to evaluate the performance of single sprout node against two sprout nodes in the Clearwater IMS for the SIP call load. (using multi VM based CW IMS image) This is to demonstrate the necessity and advantage of scaling out the sprout node.

So what we are attempting is to find out the overload point of single sprout when calls start failing, whereas for the similar load two sprout scenario works fine. We use SIPp to emulate calls. We normally generate from 50 calls/sec and keep in increasing till 100/150 calls per second.

However when we are experimenting the above scenario (first to find the overload point for single sprout), we  are finding inconsistent observation. Some time single sprout creates call failures for even 50 calls/ sec, but if we experiment after sometime single sprout is able to tolerate even more than 100 calls per seconds. Based on our study from CW website, we understand that this might be due to  dynamic throttling supported  by CW IMS nodes.  We have tried to manipulate the value of max tokens as well as the token rate to ensure there is no dynamic throttling, however couldn't find any visible improvement in the observation. Due to this we are unable to fix the overload point for single sprout hence couldn't able to do a testing for getting visible performance improvement comparison between single and two sprout nodes.

I have few queries here. Can you please help us in getting clarity here?


1)      Is there a possibility exist to disable dynamic throttling? If not, any parameter setting e.g. token related parameter will ensure throttling is not happening?

2)      Is there a predefined overload point in terms of number SIP calls/ sec for a single sprout? (we are suing single single core, 2 GB RAM, 20 GB hard disk VM for sprout)

3)      Is there any recommended parameters for this kind of testing -  in terms of SIP load ie calls/sec. any configuration parameter setting (like token as well as any other)?

4)      As per our understanding sprout is first component expected to be scaled out because it will be more loaded than any other CW IMS nodes. Is our understanding is correct?

5)      When we scale out sprout, scaling out sprout alone is enough or any other nodes also expected to be scaled out to see the performance improvement?

Thanks,
Jackson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170303/28ed078e/attachment.html>

From a6160107 at gmail.com  Wed Mar  8 03:29:02 2017
From: a6160107 at gmail.com (=?UTF-8?B?5rqr5L+K57at?=)
Date: Wed, 8 Mar 2017 16:29:02 +0800
Subject: [Project Clearwater] About Clearwater Register Processing
Message-ID: <CAOgshDs=66jvDZ9QnokGOVo4qiQY8x6SvK4=dm2fxB4RdTFcGg@mail.gmail.com>

Dear All,

I have some questions about Clearwater Register flow between Homestead and
Sprout,
according to
http://www.projectclearwater.org/technical/clearwater-architecture/,
I find the following descriptions,
    Sprout
  The Sprout nodes act as a horizontally scalable, combined SIP registrar
and authoritative routing proxy, and handle client authentication.
  The Sprout cluster includes a redundant memcached cluster storing client
registration data and other long-lived state.

    Homestead
Homestead provides a Web services interface to Sprout for retrieving
authentication credentials and user profile information.

So, Homestead is just a interface between Sprout and HSS to help Sprout get
user profile from HSS ,and doesn't process message for client
authentication?

The mainly component being charged of authentication is Sprout?

I had set icscf with Sprout, called sprout(i), and when I use wireshark
capture the packets of registration, I find that packets didn't pass
through Sprout cluster, and just pass through my sprout(i).
Does my sprout(i) deal with user authentication or the homestead do?


Thanks,

Eric
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170308/fe2c0747/attachment.html>

From Sebastian.Rex at metaswitch.com  Wed Mar  8 04:31:23 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Wed, 8 Mar 2017 09:31:23 +0000
Subject: [Project Clearwater] About Clearwater Register Processing
In-Reply-To: <CAOgshDs=66jvDZ9QnokGOVo4qiQY8x6SvK4=dm2fxB4RdTFcGg@mail.gmail.com>
References: <CAOgshDs=66jvDZ9QnokGOVo4qiQY8x6SvK4=dm2fxB4RdTFcGg@mail.gmail.com>
Message-ID: <SN1PR02MB1664462C2A4AEC483E00D1788F2E0@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

If you?re using an external HSS, then Homestead just acts as a cache for the HSS data. The actual authentication processing is handled by Sprout.

The reason that you?re not seeing SIP messages between Sprout and Homestead is that the interface between the two is HTTP, not SIP. When Sprout receives the REGISTER request, it gets authentication data from Homestead over HTTP, and then Sprout uses the authorization data on the REGISTER to allow/forbid the user.

The full flow for a REGISTER can be seen in the ?Mainline Flows? section here: http://www.projectclearwater.org/technical/call-flows/

I hope that helps,
Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of ???
Sent: 08 March 2017 08:29
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] About Clearwater Register Processing

Dear All,

I have some questions about Clearwater Register flow between Homestead and Sprout,
according to http://www.projectclearwater.org/technical/clearwater-architecture/,
I find the following descriptions,
    Sprout
  The Sprout nodes act as a horizontally scalable, combined SIP registrar and authoritative routing proxy, and handle client authentication.
  The Sprout cluster includes a redundant memcached cluster storing client registration data and other long-lived state.

    Homestead
Homestead provides a Web services interface to Sprout for retrieving authentication credentials and user profile information.

So, Homestead is just a interface between Sprout and HSS to help Sprout get user profile from HSS ,and doesn't process message for client authentication?

The mainly component being charged of authentication is Sprout?

I had set icscf with Sprout, called sprout(i), and when I use wireshark capture the packets of registration, I find that packets didn't pass through Sprout cluster, and just pass through my sprout(i).
Does my sprout(i) deal with user authentication or the homestead do?

Thanks,

Eric
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170308/40a72462/attachment.html>

From richard.whitehouse at projectclearwater.org  Wed Mar  8 04:50:40 2017
From: richard.whitehouse at projectclearwater.org (Richard Whitehouse (projectclearwater.org))
Date: Wed, 8 Mar 2017 09:50:40 +0000
Subject: [Project Clearwater] Sprout and third-party registrations
In-Reply-To: <CY4PR18MB1336E629976705422483350CA9280@CY4PR18MB1336.namprd18.prod.outlook.com>
References: <CY4PR18MB1336E629976705422483350CA9280@CY4PR18MB1336.namprd18.prod.outlook.com>
Message-ID: <BY2PR0201MB1816149A916ABBDEAC9719B8F02E0@BY2PR0201MB1816.namprd02.prod.outlook.com>

Jake,

There's quite a lot of configurability involved here, as to which registration types it should trigger on (initial registration, reregistration or deregistration) and whether the S-CSCF should include the request/response in the body.

Here's an example which provides extensive behaviour, for an AS which is contacted on TCP, using SRV records, with a domain name of "sample-as.test", sending on all registration types, and including as much information as possible.

<InitialFilterCriteria>
  <Priority>0</Priority>
  <TriggerPoint>
   <ConditionTypeCNF>0</ConditionTypeCNF>
   <SPT>
    <ConditionNegated>0</ConditionNegated>
    <Group>0</Group>
    <Method>REGISTER</Method>
    <Extension>
     <RegistrationType>0</RegistrationType>
     <RegistrationType>1</RegistrationType>
     <RegistrationType>2</RegistrationType>
    </Extension>
   </SPT>
  </TriggerPoint>
  <ApplicationServer>
   <ServerName>
     sip:sample-as.test;transport=TCP
   </ServerName>
   <DefaultHandling>0</DefaultHandling>
   <Extension>
    <IncludeRegisterRequest/>
    <IncludeRegisterResponse/>
   </Extension>
  </ApplicationServer>
</InitialFilterCriteria>

Richard

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Jake Brown
Sent: 02 March 2017 04:08
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] Sprout and third-party registrations

I am looking for a IFC example that would induce the behavior described in the manual where the S-CSCF would pass a third party registration onto an AS:

>From the online manual:

AS invocation also occurs on REGISTER - this is called third-party registration (3GPP TS 24.229 s5.4.1.7 and 7A):

  *   When a UE registers with Sprout, if the iFCs require it, it passes a third-party registration onto an AS.
  *   Message body handling for third-party registration, per 3GPP TS 24.229 s5.4.1.7A: including optionally service info, a copy of the registration, and a copy of the response.
  *   Network-initiated deregister. If the third-party registration fails and the iFC requests it, we must deregister the UE.

Thank You

Jake
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170308/032a10aa/attachment.html>

From ahmed.eldeeb at 4gtss.com  Wed Mar  8 06:12:26 2017
From: ahmed.eldeeb at 4gtss.com (Ahmed Eldeeb)
Date: Wed, 8 Mar 2017 13:12:26 +0200
Subject: [Project Clearwater] hello
Message-ID: <70209df7-dcec-9f76-67a5-6008f92a40db@4gtss.com>

I have recently installed clearwater folloiwng the manual installation 
instructions on 7 virtual machines running ubuntu.
After installation and running the machines i tried to sign in using 
zoiper application but i recieved 403 forbidden response through 
wireshark traces so i tried to check each node
i found that the homestead node status is not running
and the current log  ( var/log/homestead/homestead_current.txt ) of node 
shows that :

-----------------------------------------------------------------------------------------------------------------------------
08-03-2017 10:19:25.525 UTC Status load_monitor.cpp:105: Constructing 
LoadMonitor
08-03-2017 10:19:25.525 UTC Status load_monitor.cpp:106:    Target 
latency (usecs)   : 100000
08-03-2017 10:19:25.525 UTC Status load_monitor.cpp:107:    Max bucket 
size          : 1000
08-03-2017 10:19:25.525 UTC Status load_monitor.cpp:108:    Initial 
token fill rate/s: 100.000000
08-03-2017 10:19:25.525 UTC Status load_monitor.cpp:109:    Min token 
fill rate/s    : 10.000000
08-03-2017 10:19:25.525 UTC Status dnscachedresolver.cpp:150: Creating 
Cached Resolver using servers:
08-03-2017 10:19:25.525 UTC Status dnscachedresolver.cpp:160: 127.0.0.1
08-03-2017 10:19:25.525 UTC Status a_record_resolver.cpp:54: Created 
ARecordResolver
08-03-2017 10:19:25.525 UTC Status a_record_resolver.cpp:54: Created 
ARecordResolver
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:181: Configuring 
store connection
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:182: Hostname:  
127.0.0.1
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:183: Port:      9160
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:211: Configuring 
store worker pool
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:212: Threads:   10
08-03-2017 10:19:25.525 UTC Status cassandra_store.cpp:213:   Max Queue: 0
08-03-2017 10:19:25.526 UTC Error main.cpp:756: Failed to initialize the 
Cassandra cache with error code 1.
08-03-2017 10:19:25.526 UTC Status main.cpp:757: Homestead is shutting down

----------------------------------------------------------------------------------------------------------------------------------------
and the file "/var/log/homestead/homestead_err.log" contains

------------------------------------------------------------------------------------------
TSocket::open() error on socket (after THRIFT_POLL) <Host: 127.0.0.1 
Port: 9160>Connection refused
------------------------------------------------------------------------------------------


although the cassandra is running but the schemas created by homestead 
(homestead_cache) seems to be doesnot exist so could you please sent me 
these scripts



From ahmed.eldeeb at 4gtss.com  Wed Mar  8 16:15:39 2017
From: ahmed.eldeeb at 4gtss.com (Ahmed Eldeeb)
Date: Wed, 8 Mar 2017 23:15:39 +0200
Subject: [Project Clearwater] Hello
Message-ID: <fac20f10-1c4a-fda1-52b8-0ee199fccb3b@4gtss.com>

I tried to install clearwater in 7 machines and i found that homer node 
didnot create the schemes for cassandra when trying to troubleshooting 
following the steps in this link 
http://clearwater.readthedocs.io/en/stable/Troubleshooting_and_Recovery.html

i found that the files |homer.sh , ||homestead_cache.sh , 
||homestead_provisioning.sh are not exists so could you please send me 
this files to create schema
|

|thanks in advance
|

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170308/645f374e/attachment.html>

From Sebastian.Rex at metaswitch.com  Fri Mar 10 10:31:05 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Fri, 10 Mar 2017 15:31:05 +0000
Subject: [Project Clearwater] Hello
In-Reply-To: <fac20f10-1c4a-fda1-52b8-0ee199fccb3b@4gtss.com>
References: <fac20f10-1c4a-fda1-52b8-0ee199fccb3b@4gtss.com>
Message-ID: <SN1PR02MB1664CDCC4A27F2E693AD3FD88F200@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

First off ? it doesn?t look like you?re signed up to the mailing list. We recommend you sign up to the list by clicking the ?Mailing List Signup? link from here: http://www.projectclearwater.org/community.

As for your problem ? are you saying that the file ?usr/share/clearwater/cassandra-schemas/homer.sh? doesn?t exist on your homer node? That should have been installed when you installed the ?homer-cassandra? package, which should have been installed as a dependency of the ?homer-node? package.

Did you install this node manually? If so, it?s possibly that you only installed the ?homer? package, not the ?homer-node? package. You should be able to see if the ?homer-node? package is installed by running:

dpkg -s homer-node

If it?s not installed, you?ll have to install it by running:

sudo DEBIAN_FRONTEND=noninteractive apt-get install homer-node ?yes

Once you?ve done that, you will probably have to recreate the schema manually by running:

/usr/share/clearwater/cassandra-schemas/homer.sh

Let me know if that helps,

Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Ahmed Eldeeb
Sent: 08 March 2017 21:16
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] Hello


I tried to install clearwater in 7 machines and i found that homer node didnot create the schemes for cassandra when trying to troubleshooting following the steps in this link http://clearwater.readthedocs.io/en/stable/Troubleshooting_and_Recovery.html

i found that the files homer.sh , homestead_cache.sh , homestead_provisioning.sh are not exists so could you please send me this files to create schema

thanks in advance
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170310/53dad069/attachment.html>

From Ying.Huang at metaswitch.com  Fri Mar 10 11:48:57 2017
From: Ying.Huang at metaswitch.com (Ying Huang)
Date: Fri, 10 Mar 2017 16:48:57 +0000
Subject: [Project Clearwater] Release note for Aragorn
Message-ID: <MWHPR02MB24772B42C28A291F8453F64EF8200@MWHPR02MB2477.namprd02.prod.outlook.com>

Hi all,

The release for Project Clearwater sprint "Aragorn" has been cut. The code for this release is tagged as release-118 in GitHub.
This release includes the following bug fixes:


?         Sprout converts a 503 Service Unavailable from Homestead into a 404 Not Found (https://github.com/Metaswitch/sprout/issues/1623)



?         Calls to +22233 and +5678;rn=+22233 are routed differently when the default route is used (https://github.com/Metaswitch/sprout/issues/1621)



?         Sprout crash at high traffic load when configured with a CFS TAS. (https://github.com/Metaswitch/sprout/issues/981)



?         Monit does not monitor ralf_uptime or poll_ralf when Ralf has an IPv6 signalling address (https://github.com/Metaswitch/clearwater-monit/issues/52)



?         upload_shared_config fails when ? characters are in shared_config (https://github.com/Metaswitch/clearwater-etcd/issues/414)



?         etcd memory usage grows unbounded on all nodes, eventually crashing cluster (https://github.com/Metaswitch/clearwater-etcd/issues/399)


Note that in this release, we are changing the way that Geographically Redundant (GR) deployments are set up. Specifically, we were splitting the etcd cluster so that there is one cluster for each site, rather than a single cluster spanning both. Because of this change, there are some one-time extra steps that must be taken prior to upgrading to this release. These steps differ depending on whether you are using a GR deployment or not:
If you are using a non-GR deployment (which is the norm):
Before you upgrade to this release, you must perform the following steps on any one node:

  1.  Add sprout_registration_store=sprout.<zone> to /etc/clearwater/shared_config
  2.  If you are using Ralf nodes, add ralf_session_store=ralf.<zone> to /etc/clearwater/shared_config
  3.  Run cw-upload_shared_config
  4.  Wait for all nodes to pick up the  new config by using cw-check_restart_queue_state to check when all nodes have restarted
Once this is done and all nodes have restarted, you can upgrade as normal.
If you are using a GR deployment:
Because of the move to split the etcd clusters across sites, upgrading a GR deployment is not supported using the usual methods. If you want help upgrading a GR deployment, contact us on the mailing list for instructions.

If you are deploying an all-in-one node, the standard image (http://vm-images.cw-ngv.com/cw-aio.ova) has been updated for this release.

Thanks,
Ying


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170310/c067a778/attachment.html>

From Sebastian.Rex at metaswitch.com  Mon Mar 13 07:21:37 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Mon, 13 Mar 2017 11:21:37 +0000
Subject: [Project Clearwater] Fwd: manually install clearwater on
 OpenStack - SIP error 408
In-Reply-To: <CAOJ1h8VJ2_3zR1-xVy5hGwSojkegbpsU-TED_eeZkZfbjNGraQ@mail.gmail.com>
References: <CAOJ1h8W6g-9DNnLdY_=1ze4=MLnhiZVnWmAPrfKghzsSVjFWpw@mail.gmail.com>
	<CAOJ1h8VoY0wxRnyANV0TH=7NJHRE4-ceTZkNaPPVqJBUnnMS9g@mail.gmail.com>
	<SN1PR02MB16643368178281492A60A5E38F290@SN1PR02MB1664.namprd02.prod.outlook.com>
	<CAOJ1h8VJ2_3zR1-xVy5hGwSojkegbpsU-TED_eeZkZfbjNGraQ@mail.gmail.com>
Message-ID: <SN1PR02MB166417FBDE6CB694869E71148F250@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

Could you turn on debug logging on Bono, by following the steps here: http://clearwater.readthedocs.io/en/stable/Troubleshooting_and_Recovery.html#bono

Then if you reproduce the problem, and send us the logs from the time of the reproduced problem (the logs are in /var/log/bono/bono*.txt) we can take a look at those and see if that shows where the problem is.

Thanks,
Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Xiaobai Li
Sent: 01 March 2017 22:24
To: clearwater at lists.projectclearwater.org
Subject: Re: [Project Clearwater] Fwd: manually install clearwater on OpenStack - SIP error 408

Hi Seb,

Thanks a lot for your reply. Actually, currently I directly got 408 from Bono node for REGISTER request. Here is the current packet capture from Bono. It seems like after X-Lite sends a REGISTER request to Bono, the Bono gave me a 408 error. The Bono didn't send the REGISTER request to Sprout. The only thing that I changed is the DNS server reverse zone configuration. Hope I could receive some suggestions from your side.

Thanks!

10.145.15.10.57729 > bono.sip: Flags [P.], cksum 0x46e9 (correct), seq 1115:1671, ack 755, win 32768, length 556
        0x0000:  fa16 3e09 2d9d fa16 3ecc 35dc 0800 4500  ..>.-...>.5...E.
        0x0010:  0254 9dce 0000 3d06 170c 0a91 0f0a ac1b  .T....=.........
        0x0020:  0114 e181 13c4 4fab 5f38 386f 3984 5018  ......O._88o9.P.
        0x0030:  8000 46e9 0000 5245 4749 5354 4552 2073  ..F...REGISTER.s
        0x0040:  6970 3a69 6d73 2e68 6f6d 2053 4950 2f32  ip:ims.hom.SIP/2
        0x0050:  2e30 0d0a 5669 613a 2053 4950 2f32 2e30  .0..Via:.SIP/2.0
        0x0060:  2f54 4350 2031 302e 3134 352e 3135 2e31  /TCP.10.145.15.1
        0x0070:  303a 3537 3732 383b 6272 616e 6368 3d7a  0:57728;branch=z
        0x0080:  3968 4734 624b 2d35 3234 3238 372d 312d  9hG4bK-524287-1-
        0x0090:  2d2d 3065 6137 3165 3164 3332 6336 6633  --0ea71e1d32c6f3
        0x00a0:  3266 3b72 706f 7274 0d0a 4d61 782d 466f  2f;rport..Max-Fo
        0x00b0:  7277 6172 6473 3a20 3730 0d0a 436f 6e74  rwards:.70..Cont
        0x00c0:  6163 743a 203c 7369 703a 3635 3035 3535  act:.<sip:650555
        0x00d0:  3039 3234 4031 302e 3134 352e 3135 2e31  0924 at 10.145.15.1<mailto:0924 at 10.145.15.1>
        0x00e0:  303a 3537 3732 383b 7269 6e73 7461 6e63  0:57728;rinstanc
        0x00f0:  653d 3362 6534 3461 6138 6463 3439 3466  e=3be44aa8dc494f
        0x0100:  3764 3b74 7261 6e73 706f 7274 3d74 6370  7d;transport=tcp
        0x0110:  3e0d 0a54 6f3a 2022 5869 616f 6261 6922  >..To:."Xiaobai"
        0x0120:  3c73 6970 3a36 3530 3535 3530 3932 3440  <sip:6505550924@
        0x0130:  696d 732e 686f 6d3e 0d0a 4672 6f6d 3a20  ims.hom>..From:.
        0x0140:  2258 6961 6f62 6169 223c 7369 703a 3635  "Xiaobai"<sip:65
        0x0150:  3035 3535 3039 3234 4069 6d73 2e68 6f6d  05550924 at ims.hom<mailto:05550924 at ims.hom>
        0x0160:  3e3b 7461 673d 3638 6636 3239 3431 0d0a  >;tag=68f62941..
        0x0170:  4361 6c6c 2d49 443a 2038 3231 3538 5a6a  Call-ID:.82158Zj
        0x0180:  526a 4f44 6330 4e7a 5a69 4e6d 526a 4f54  RjODc0NzZiNmRjOT
        0x0190:  5a6b 5932 457a 4e7a 5931 4d6a 6730 4e44  ZkY2EzNzY1Mjg0ND
        0x01a0:  4933 5a47 5933 4e6a 4d0d 0a43 5365 713a  I3ZGY3NjM..CSeq:
        0x01b0:  2033 2052 4547 4953 5445 520d 0a45 7870  .3.REGISTER..Exp
        0x01c0:  6972 6573 3a20 3336 3030 0d0a 416c 6c6f  ires:.3600..Allo
        0x01d0:  773a 2053 5542 5343 5249 4245 2c20 4e4f  w:.SUBSCRIBE,.NO
        0x01e0:  5449 4659 2c20 494e 5649 5445 2c20 4143  TIFY,.INVITE,.AC
        0x01f0:  4b2c 2043 414e 4345 4c2c 2042 5945 2c20  K,.CANCEL,.BYE,.
        0x0200:  5245 4645 522c 2049 4e46 4f2c 204f 5054  REFER,.INFO,.OPT
        0x0210:  494f 4e53 2c20 4d45 5353 4147 450d 0a55  IONS,.MESSAGE..U
        0x0220:  7365 722d 4167 656e 743a 2058 2d4c 6974  ser-Agent:.X-Lit
        0x0230:  6520 7265 6c65 6173 6520 342e 392e 3620  e.release.4.9.6.
        0x0240:  7374 616d 7020 3832 3135 380d 0a43 6f6e  stamp.82158..Con
        0x0250:  7465 6e74 2d4c 656e 6774 683a 2030 0d0a  tent-Length:.0..
        0x0260:  0d0a                                     ..
22:09:54.805344 IP (tos 0x0, ttl 64, id 15286, offset 0, flags [DF], proto TCP (6), length 417)
    bono.sip > 10.145.15.10.57729: Flags [P.], cksum 0xc85d (incorrect -> 0x771f), seq 755:1132, ack 1671, win 31136, length 377
        0x0000:  fa16 3ecc 35dc fa16 3e09 2d9d 0800 4500  ..>.5...>.-...E.
        0x0010:  01a1 3bb6 4000 4006 36d7 ac1b 0114 0a91  ..;. at .@.6.......
        0x0020:  0f0a 13c4 e181 386f 3984 4fab 6164 5018  ......8o9.O.adP.
        0x0030:  79a0 c85d 0000 5349 502f 322e 3020 3430  y..]..SIP/2.0.40
        0x0040:  3820 5265 7175 6573 7420 5469 6d65 6f75  8.Request.Timeou
        0x0050:  740d 0a56 6961 3a20 5349 502f 322e 302f  t..Via:.SIP/2.0/
        0x0060:  5443 5020 3130 2e31 3435 2e31 352e 3130  TCP.10.145.15.10
        0x0070:  3a35 3737 3238 3b72 706f 7274 3d35 3737  :57728;rport=577
        0x0080:  3239 3b72 6563 6569 7665 643d 3130 2e31  29;received=10.1
        0x0090:  3435 2e31 352e 3130 3b62 7261 6e63 683d  45.15.10;branch=
        0x00a0:  7a39 6847 3462 4b2d 3532 3432 3837 2d31  z9hG4bK-524287-1
        0x00b0:  2d2d 2d30 6561 3731 6531 6433 3263 3666  ---0ea71e1d32c6f
        0x00c0:  3332 660d 0a43 616c 6c2d 4944 3a20 3832  32f..Call-ID:.82
        0x00d0:  3135 385a 6a52 6a4f 4463 304e 7a5a 694e  158ZjRjODc0NzZiN
        0x00e0:  6d52 6a4f 545a 6b59 3245 7a4e 7a59 314d  mRjOTZkY2EzNzY1M
        0x00f0:  6a67 304e 4449 335a 4759 334e 6a4d 0d0a  jg0NDI3ZGY3NjM..
        0x0100:  4672 6f6d 3a20 2258 6961 6f62 6169 2220  From:."Xiaobai".
        0x0110:  3c73 6970 3a36 3530 3535 3530 3932 3440  <sip:6505550924@
        0x0120:  696d 732e 686f 6d3e 3b74 6167 3d36 3866  ims.hom>;tag=68f
        0x0130:  3632 3934 310d 0a54 6f3a 2022 5869 616f  62941..To:."Xiao
        0x0140:  6261 6922 203c 7369 703a 3635 3035 3535  bai".<sip:650555
        0x0150:  3039 3234 4069 6d73 2e68 6f6d 3e3b 7461  0924 at ims.hom>;ta<mailto:0924 at ims.hom%3e;ta>
        0x0160:  673d 7a39 6847 3462 4b2d 3532 3432 3837  g=z9hG4bK-524287
        0x0170:  2d31 2d2d 2d30 6561 3731 6531 6433 3263  -1---0ea71e1d32c
        0x0180:  3666 3332 660d 0a43 5365 713a 2033 2052  6f32f..CSeq:.3.R
        0x0190:  4547 4953 5445 520d 0a43 6f6e 7465 6e74  EGISTER..Content
        0x01a0:  2d4c 656e 6774 683a 2020 300d 0a0d 0a    -Length:..0....
22:09:54.807608 IP (tos 0x0, ttl 61, id 40399, offset 0, flags [none], proto TCP (6), length 40)




2017-03-01 1:31 GMT-08:00 Sebastian Rex <Sebastian.Rex at metaswitch.com<mailto:Sebastian.Rex at metaswitch.com>>:
Hi,

It looks like you?re getting a 200 OK to the REGISTER request, but you?re getting a 408 to a subsequent SUBSCRIBE request (you can see this in the packet capture you attached). So the client should be registered correctly. Are calls working?

The SUBSCRIBE message appears to be for:


?application/simple-message-summary?



which is used for message waiting indication. If you don?t expect to be using MWI, then you should turn off the SUBSCRIBE in X-Lite. If memory serves, there?s a ?Voicemail? tab in the X-Lite Account Settings which you can use to turn this off.



All that we can see from the snippet of sprout logs that you included is that the OPTIONS poll succeeds (this is sprout?s health-checking poll).



Hope that helps,

Seb.

From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org<mailto:clearwater-bounces at lists.projectclearwater.org>] On Behalf Of Xiaobai Li
Sent: 28 February 2017 23:34
To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>
Subject: [Project Clearwater] Fwd: manually install clearwater on OpenStack - SIP error 408

Hi guys,

I wrote an email before to ask an 408 error when registering manually installed clearwater through X-Lite. Currently, when I am trying to register, it will directly give me an 408 time out error. Here I attached the log information on sprout. Hope anyone who could help me to figure out what's going on.

The log information on sprout node as follows.

Thanks a lot!

--start msg--

OPTIONS sip:poll-sip at 172.27.1.21:5054<http://sip:poll-sip at 172.27.1.21:5054/> SIP/2.0
Via: SIP/2.0/TCP 172.27.1.21;rport;branch=z9hG4bK-4490
Max-Forwards: 2
To: <sip:poll-sip at 172.27.1.21:5054<http://sip:poll-sip at 172.27.1.21:5054/>>
From: poll-sip <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=4490
Call-ID: poll-sip-4490
CSeq: 4490 OPTIONS
Contact: <sip:172.27.1.21>
Accept: application/sdp
Content-Length: 0
User-Agent: poll-sip
^M

--end msg--
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI as 3
28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:213: Skipping SAS logging for OPTIONS request
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:264: Queuing cloned received message 0x7fab0800d108 for worker threads
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:150: Worker thread dequeue message 0x7fab0800d108
28-02-2017 23:26:34.660 UTC Debug pjsip: sip_endpoint.c Distributing rdata to modules: Request msg OPTIONS/cseq=4490 (rdata0x7fab0800d108)
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
28-02-2017 23:26:34.660 UTC Debug uri_classifier.cpp:204: Classified URI as 3
28-02-2017 23:26:34.660 UTC Debug pjsip:       endpoint Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) created
28-02-2017 23:26:34.660 UTC Verbose common_sip_processing.cpp:136: TX 268 bytes Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50) to TCP 172.27.1.21:53896<http://172.27.1.21:53896/>:
--start msg--

SIP/2.0 200 OK^M
Via: SIP/2.0/TCP 172.27.1.21;rport=53896;received=172.27.1.21;branch=z9hG4bK-4490^M
Call-ID: poll-sip-4490^M
From: "poll-sip" <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=4490^M
To: <sip:poll-sip at 172.27.1.21<mailto:sip%3Apoll-sip at 172.27.1.21>>;tag=z9hG4bK-4490^M
CSeq: 4490 OPTIONS^M
Content-Length:  0^M
^M

--end msg--
28-02-2017 23:26:34.660 UTC Debug common_sip_processing.cpp:262: Skipping SAS logging for OPTIONS response
28-02-2017 23:26:34.660 UTC Debug pjsip: tdta0x7fab1400 Destroying txdata Response msg 200/OPTIONS/cseq=4490 (tdta0x7fab14009f50)
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:200: Worker thread completed processing message 0x7fab0800d108
28-02-2017 23:26:34.660 UTC Debug thread_dispatcher.cpp:206: Request latency = 125us
28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:342: Process request for URL /ping, args (null)
28-02-2017 23:26:34.681 UTC Verbose httpstack.cpp:90: Sending response 200 to request for URL /ping, args (null)
28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP connection closed
28-02-2017 23:26:36.662 UTC Status connection_tracker.cpp:92: Connection 0x7fab0800a428 has been destroyed
28-02-2017 23:26:36.662 UTC Verbose pjsip: tcps0x7fab0800 TCP transport destroyed with reason 70016: End of file (PJ_EEOF)

---------- Forwarded message ----------
From: Xiaobai Li <leeshirley2002 at gmail.com<mailto:leeshirley2002 at gmail.com>>
Date: 2017-02-06 20:15 GMT-08:00
Subject: manually install clearwater on OpenStack - SIP error 408
To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>
Hi guys,

I followed the manual installation instructions and successfully installed clearwater on Openstack using 7 vms (1 private DNS zone). I used the SIP client X-lite and successfully registered a user. However, sometimes the X-lite gives me a SIP error 408 and I couldn't make calls between registered users.
Here is my settings for the X-lite:
General:

User ID: 6505550631<tel:(650)%20555-0631>
Domain: ims.hom
password: *******
Display name: **
Authorization name: 6505550631<tel:(650)%20555-0631>@ims.hom

Domain Proxy:
Send outbound via:
proxy: {bono ip address}

Topology:
sever address: ims.hom
Username: 6505550631<tel:(650)%20555-0631>@ims.hom
password: ******


Here I also attached the tcpdump between bono and my SIP client when registering a user, after 200 for registration it gives me 408 error for subscribe.

Hope anyone can help me to figure out this problem. Thanks a lot!

Shirley





_______________________________________________
Clearwater mailing list
Clearwater at lists.projectclearwater.org<mailto:Clearwater at lists.projectclearwater.org>
http://lists.projectclearwater.org/mailman/listinfo/clearwater_lists.projectclearwater.org

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170313/4d28155b/attachment.html>

From ahmed.eldeeb at 4gtss.com  Tue Mar 14 09:57:37 2017
From: ahmed.eldeeb at 4gtss.com (Ahmed Eldeeb)
Date: Tue, 14 Mar 2017 15:57:37 +0200
Subject: [Project Clearwater] Hello
Message-ID: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>

I am installing clearwater in 3 different machines and i am facing a 
problem when trying to register using zoiper when trying to register i 
received internal server error (500).

I don't know where is the problem i tired to access logs and attached it 
to email.

-------------- next part --------------
14-03-2017 13:15:22.355 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
14-03-2017 13:15:22.355 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
14-03-2017 13:15:22.355 UTC Debug handlers.cpp:201: Got authentication vector with digest 61ea8247adb95f7074d14b9cca86df99 from cache
14-03-2017 13:15:22.355 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:15:38.450 UTC Debug alarm.cpp:253: Reraising all alarms with a known state
14-03-2017 13:15:38.450 UTC Status alarm.cpp:62: homestead issued 1501.1 alarm
14-03-2017 13:16:00.583 UTC Verbose httpstack.cpp:345: Process request for URL /ping, args (null)
14-03-2017 13:16:00.583 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /ping, args (null)
14-03-2017 13:16:08.450 UTC Debug alarm.cpp:253: Reraising all alarms with a known state
14-03-2017 13:16:08.450 UTC Status alarm.cpp:62: homestead issued 1501.1 alarm
14-03-2017 13:16:30.642 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:30.642 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
14-03-2017 13:16:30.642 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:30.683 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:16:30.683 UTC Debug handlers.cpp:155: Parsed HTTP request: private ID 6505550525 at ims.cw.4gtss.com, public ID sip:6505550525 at ims.cw.4gtss.com, scheme Unknown, authorization 
14-03-2017 13:16:30.683 UTC Debug handlers.cpp:181: Querying cache for authentication vector for 6505550525 at ims.cw.4gtss.com/sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:30.683 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
14-03-2017 13:16:30.683 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
14-03-2017 13:16:30.683 UTC Debug a_record_resolver.cpp:88: Target is an IP address
14-03-2017 13:16:30.683 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
14-03-2017 13:16:30.683 UTC Debug connection_pool.h:244: Found existing connection 0x7efe80007860 in pool
14-03-2017 13:16:30.683 UTC Debug cache.cpp:673: Looking for authentication vector for 6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:30.683 UTC Debug cache.cpp:685: Checking public ID sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:30.683 UTC Debug cache.cpp:695: Issuing cache query
14-03-2017 13:16:30.684 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
14-03-2017 13:16:30.686 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
14-03-2017 13:16:30.686 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
14-03-2017 13:16:30.686 UTC Debug communicationmonitor.cpp:82: Checking communication changes - successful attempts 2, failures 0
14-03-2017 13:16:30.686 UTC Debug handlers.cpp:201: Got authentication vector with digest 61ea8247adb95f7074d14b9cca86df99 from cache
14-03-2017 13:16:30.686 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:16:33.263 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:33.263 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
14-03-2017 13:16:33.263 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:33.279 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:16:33.279 UTC Debug handlers.cpp:155: Parsed HTTP request: private ID 6505550525 at ims.cw.4gtss.com, public ID sip:6505550525 at ims.cw.4gtss.com, scheme Unknown, authorization 
14-03-2017 13:16:33.279 UTC Debug handlers.cpp:181: Querying cache for authentication vector for 6505550525 at ims.cw.4gtss.com/sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:33.279 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
14-03-2017 13:16:33.279 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
14-03-2017 13:16:33.279 UTC Debug a_record_resolver.cpp:88: Target is an IP address
14-03-2017 13:16:33.279 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
14-03-2017 13:16:33.279 UTC Debug connection_pool.h:244: Found existing connection 0x7efe80007860 in pool
14-03-2017 13:16:33.279 UTC Debug cache.cpp:673: Looking for authentication vector for 6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:33.279 UTC Debug cache.cpp:685: Checking public ID sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:33.279 UTC Debug cache.cpp:695: Issuing cache query
14-03-2017 13:16:33.280 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
14-03-2017 13:16:33.282 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
14-03-2017 13:16:33.282 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
14-03-2017 13:16:33.282 UTC Debug handlers.cpp:201: Got authentication vector with digest 61ea8247adb95f7074d14b9cca86df99 from cache
14-03-2017 13:16:33.282 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com








^C[homestead-sprout]deeb at sprout:~$ 
[homestead-sprout]deeb at sprout:~$ sudo tailf /var/log/homestead/homestead_current.txt 
14-03-2017 13:16:37.833 UTC Debug cache.cpp:695: Issuing cache query
14-03-2017 13:16:37.835 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
14-03-2017 13:16:37.837 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
14-03-2017 13:16:37.837 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
14-03-2017 13:16:37.837 UTC Debug handlers.cpp:201: Got authentication vector with digest 61ea8247adb95f7074d14b9cca86df99 from cache
14-03-2017 13:16:37.837 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:16:37.837 UTC Info load_monitor.cpp:232: Accepted 100.000000% of requests, latency error = -0.978120, overload responses = 0
14-03-2017 13:16:37.837 UTC Status load_monitor.cpp:285: Maximum incoming request rate/second unchanged - only handled 22 requests in last 109256ms, minimum threshold for a change is 4552.333008
14-03-2017 13:16:38.451 UTC Debug alarm.cpp:253: Reraising all alarms with a known state
14-03-2017 13:16:38.451 UTC Status alarm.cpp:62: homestead issued 1501.1 alarm
14-03-2017 13:16:42.019 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:42.019 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
14-03-2017 13:16:42.019 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
14-03-2017 13:16:42.039 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com
14-03-2017 13:16:42.039 UTC Debug handlers.cpp:155: Parsed HTTP request: private ID 6505550525 at ims.cw.4gtss.com, public ID sip:6505550525 at ims.cw.4gtss.com, scheme Unknown, authorization 
14-03-2017 13:16:42.039 UTC Debug handlers.cpp:181: Querying cache for authentication vector for 6505550525 at ims.cw.4gtss.com/sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:42.039 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
14-03-2017 13:16:42.039 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
14-03-2017 13:16:42.040 UTC Debug a_record_resolver.cpp:88: Target is an IP address
14-03-2017 13:16:42.040 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
14-03-2017 13:16:42.040 UTC Debug connection_pool.h:244: Found existing connection 0x7efe80007860 in pool
14-03-2017 13:16:42.040 UTC Debug cache.cpp:673: Looking for authentication vector for 6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:42.040 UTC Debug cache.cpp:685: Checking public ID sip:6505550525 at ims.cw.4gtss.com
14-03-2017 13:16:42.040 UTC Debug cache.cpp:695: Issuing cache query
14-03-2017 13:16:42.041 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
14-03-2017 13:16:42.042 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
14-03-2017 13:16:42.042 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
14-03-2017 13:16:42.043 UTC Debug handlers.cpp:201: Got authentication vector with digest 61ea8247adb95f7074d14b9cca86df99 from cache
14-03-2017 13:16:42.043 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550525%40ims.cw.4gtss.com/av, args impu=sip%3A6505550525%40ims.cw.4gtss.com

-------------- next part --------------
Monit 5.18.1 uptime: 1h 17m

Process 'sprout_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1499
  parent pid                   1
  uid                          998
  effective uid                998
  gid                          998
  uptime                       1h 17m
  threads                      148
  children                     0
  cpu                          0.7%
  cpu total                    0.7%
  memory                       0.2% [3.1 MB]
  memory total                 0.2% [3.1 MB]
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'sprout_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'poll_sprout_sip'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'poll_sprout_http'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:54

Process 'snmpd_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1589
  parent pid                   1
  uid                          120
  effective uid                120
  gid                          131
  uptime                       1h 17m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [2.7 MB]
  memory total                 0.1% [2.7 MB]
  data collected               Tue, 14 Mar 2017 15:11:54

Process 'ntp_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2087
  parent pid                   1
  uid                          116
  effective uid                116
  gid                          127
  uptime                       1h 17m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [2.8 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:54

System 'node-sprout'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  load average                 [0.00] [0.21] [0.34]
  cpu                          2.4%us 2.5%sy 1.1%wa
  memory usage                 1.6 GB [83.1%]
  swap usage                   496.6 MB [48.5%]
  uptime                       1h 17m
  boot time                    Tue, 14 Mar 2017 13:54:10
  data collected               Tue, 14 Mar 2017 15:11:54

Process 'nginx_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1583
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       1h 17m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [1.1 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'nginx_ping'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                                                Dload  Upload   Total   Spent    Left  Speed
                                 0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   193  100   193    0     0  16146      0 --:--:-- --:--:-- --:--:--  188k
                               <html>
                               <head><title>301 Moved Permanently</title></head>
                               <body bgcolor="white">
                               <center><h1>301 Moved Permanently</h1></center>
                               <hr><center>nginx/1.4.6 (Ubuntu)</center>
                               </body>
                               </html>
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'nginx_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:54

Program 'monit_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:54

Process 'memento_process'
  status                       Execution failed | Does not exist
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'memento_uptime'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Program 'poll_memento'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Program 'poll_memento_https'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Process 'memcached_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3169
  parent pid                   1
  uid                          119
  effective uid                119
  gid                          130
  uptime                       1h 15m
  threads                      6
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [1.6 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'memcached_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'poll_memcached'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:13

Process 'homestead_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3208
  parent pid                   1
  uid                          989
  effective uid                989
  gid                          989
  uptime                       1h 15m
  threads                      121
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.0% [0 B]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'homestead_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'poll_homestead'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'check_cx_health'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              1
  last output                  Traceback (most recent call last):
                                 File "/usr/share/clearwater/bin/check_cx_health.py", line 64, in <module>
                                   import netsnmp
                               ImportError: No module named netsnmp
  data collected               Tue, 14 Mar 2017 15:11:13

Process 'homestead-prov_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          13588
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       38m
  threads                      6
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       1.1% [22.9 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'poll_homestead-prov'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:13

Process 'clearwater_queue_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2678
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       1h 15m
  threads                      10
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.5% [10.2 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:13

Program 'clearwater_queue_manager_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:13

Process 'etcd_process'
  status                       Execution failed | Does not exist
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'etcd_uptime'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Program 'poll_etcd_cluster'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Program 'poll_etcd'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 14 Mar 2017 13:56:18

Process 'clearwater_diags_monitor_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1488
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       1h 16m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [2.1 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Process 'clearwater_config_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2606
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       1h 15m
  threads                      8
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.5% [10.7 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Process 'clearwater_cluster_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2565
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       1h 15m
  threads                      5
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.3% [5.1 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Process 'cassandra_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2580
  parent pid                   1
  uid                          117
  effective uid                117
  gid                          128
  uptime                       1h 15m
  threads                      99
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       67.1% [1.3 GB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'cassandra_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'poll_cassandra'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'poll_cqlsh'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:44

Process 'chronos_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2764
  parent pid                   1
  uid                          992
  effective uid                992
  gid                          992
  uptime                       1h 15m
  threads                      235
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.0% [764 kB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'chronos_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'poll_chronos'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 14 Mar 2017 15:11:44

Process 'astaire_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2478
  parent pid                   1
  uid                          996
  effective uid                996
  gid                          996
  uptime                       1h 15m
  threads                      19
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.2% [4.7 MB]
  memory total                 0.0% [0 B]
  data collected               Tue, 14 Mar 2017 15:11:44

Program 'astaire_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 14 Mar 2017 15:11:44

-------------- next part --------------
Monit 5.18.1 uptime: 1h 17m
 Service Name                     Status                      Type          
 node-sprout                      Running                     System        
 sprout_process                   Running                     Process       
 snmpd_process                    Running                     Process       
 ntp_process                      Running                     Process       
 nginx_process                    Running                     Process       
 memento_process                  Execution failed | Does...  Process       
 memcached_process                Running                     Process       
 homestead_process                Running                     Process       
 homestead-prov_process           Running                     Process       
 clearwater_queue_manager_pro...  Running                     Process       
 etcd_process                     Execution failed | Does...  Process       
 clearwater_diags_monitor_pro...  Running                     Process       
 clearwater_config_manager_pr...  Running                     Process       
 clearwater_cluster_manager_p...  Running                     Process       
 cassandra_process                Running                     Process       
 chronos_process                  Running                     Process       
 astaire_process                  Running                     Process       
 sprout_uptime                    Status ok                   Program       
 poll_sprout_sip                  Status ok                   Program       
 poll_sprout_http                 Status ok                   Program       
 nginx_ping                       Status ok                   Program       
 nginx_uptime                     Status ok                   Program       
 monit_uptime                     Status ok                   Program       
 memento_uptime                   Wait parent                 Program       
 poll_memento                     Wait parent                 Program       
 poll_memento_https               Wait parent                 Program       
 memcached_uptime                 Status ok                   Program       
 poll_memcached                   Status ok                   Program       
 homestead_uptime                 Status ok                   Program       
 poll_homestead                   Status ok                   Program       
 check_cx_health                  Status ok                   Program       
 poll_homestead-prov              Status ok                   Program       
 clearwater_queue_manager_uptime  Status ok                   Program       
 etcd_uptime                      Wait parent                 Program       
 poll_etcd_cluster                Wait parent                 Program       
 poll_etcd                        Wait parent                 Program       
 cassandra_uptime                 Status ok                   Program       
 poll_cassandra                   Status ok                   Program       
 poll_cqlsh                       Status ok                   Program       
 chronos_uptime                   Status ok                   Program       
 poll_chronos                     Status ok                   Program       
 astaire_uptime                   Status ok                   Program       
-------------- next part --------------
14-03-2017 13:14:22.991 UTC Debug pjsip: tdta0x7fb00802 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fb008022760)
14-03-2017 13:14:22.991 UTC Debug basicproxy.cpp:534: Free un-used best response
14-03-2017 13:14:22.991 UTC Debug pjsip: tdta0x7fb00803 Destroying txdata Response msg 408/REGISTER/cseq=1 (tdta0x7fb008030a50)
14-03-2017 13:14:22.991 UTC Debug basicproxy.cpp:555: BasicProxy::UASTsx destructor completed
14-03-2017 13:14:22.991 UTC Debug pjsip: tdta0x7fb00806 Destroying txdata Response msg 500/REGISTER/cseq=1 (tdta0x7fb00806e960)
14-03-2017 13:14:22.992 UTC Debug pjsip: tsx0x7fb00800f Transaction destroyed!
14-03-2017 13:14:24.412 UTC Verbose pjsip: tcps0x7fb00c04 TCP transport destroyed normally
14-03-2017 13:14:24.663 UTC Verbose pjsip:    tcplis:5052 TCP listener 192.168.0.212:5052: got incoming TCP connection from 192.168.0.210:46941, sock=196
14-03-2017 13:14:24.664 UTC Verbose pjsip: tcps0x7fb00c02 tcp->base.local_name: 192.168.0.212
14-03-2017 13:14:24.664 UTC Verbose pjsip: tcps0x7fb00c02 TCP server transport created
14-03-2017 13:14:26.513 UTC Debug pjsip: sip_endpoint.c Processing incoming message: Request msg REGISTER/cseq=1 (rdata0x7fb00c033730)
14-03-2017 13:14:26.513 UTC Verbose common_sip_processing.cpp:120: RX 789 bytes Request msg REGISTER/cseq=1 (rdata0x7fb00c033730) from TCP 192.168.0.210:45333:
--start msg--

REGISTER sip:ims.cw.4gtss.com;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport;branch=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
Path: <sip:qBLGxQlieO at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.209:52124;rport=52124;received=192.168.0.209;branch=z9hG4bK-524287-1---f7dc3c756b6f3896
Max-Forwards: 70
Contact: <sip:6505550525 at 192.168.0.209:52124;transport=UDP;rinstance=283ff0dd3b564291>
To: <sip:6505550525 at ims.cw.4gtss.com>
From: <sip:6505550525 at ims.cw.4gtss.com>;tag=1959ab22
Call-ID: qq0DpjcQWNRPGQUHa87JrQ..
CSeq: 1 REGISTER
Expires: 6000
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
14-03-2017 13:14:26.513 UTC Debug pjutils.cpp:1689: Logging SAS Call-ID marker, Call-ID qq0DpjcQWNRPGQUHa87JrQ..
14-03-2017 13:14:26.513 UTC Debug thread_dispatcher.cpp:264: Queuing cloned received message 0x7fb00c0dc838 for worker threads
14-03-2017 13:14:26.513 UTC Debug thread_dispatcher.cpp:150: Worker thread dequeue message 0x7fb00c0dc838
14-03-2017 13:14:26.513 UTC Debug pjsip: sip_endpoint.c Distributing rdata to modules: Request msg REGISTER/cseq=1 (rdata0x7fb00c0dc838)
14-03-2017 13:14:26.513 UTC Debug uri_classifier.cpp:174: home domain: true, local_to_node: false, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
14-03-2017 13:14:26.513 UTC Debug uri_classifier.cpp:204: Classified URI as 4
14-03-2017 13:14:26.514 UTC Debug basicproxy.cpp:92: Process REGISTER request
14-03-2017 13:14:26.514 UTC Verbose sproutletproxy.cpp:507: Sproutlet Proxy transaction (0x7fb004020bc0) created
14-03-2017 13:14:26.514 UTC Debug basicproxy.cpp:1298: Report SAS start marker - trail (7a)
14-03-2017 13:14:26.514 UTC Debug pjutils.cpp:699: Cloned Request msg REGISTER/cseq=1 (rdata0x7fb00c0dc838) to tdta0x7fb004042010
14-03-2017 13:14:26.514 UTC Debug pjsip: tsx0x7fb00408d Transaction created for Request msg REGISTER/cseq=1 (rdata0x7fb00c0dc838)
14-03-2017 13:14:26.514 UTC Debug pjsip: tsx0x7fb00408d Incoming Request msg REGISTER/cseq=1 (rdata0x7fb00c0dc838) in state Null
14-03-2017 13:14:26.514 UTC Debug pjsip: tsx0x7fb00408d State changed from Null to Trying, event=RX_MSG
14-03-2017 13:14:26.514 UTC Debug basicproxy.cpp:213: tsx0x7fb00408de18 - tu_on_tsx_state UAS, TSX_STATE RX_MSG state=Trying
14-03-2017 13:14:26.514 UTC Debug pjsip:       endpoint Response msg 408/REGISTER/cseq=1 (tdta0x7fb004010500) created
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
14-03-2017 13:14:26.514 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet icscf-0x7fb004020750 for Request msg REGISTER/cseq=1 (tdta0x7fb004042010)
14-03-2017 13:14:26.514 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=1 (tdta0x7fb004042010) (818 bytes) to downstream sproutlet icscf:
--start msg--

REGISTER sip:ims.cw.4gtss.com;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=45333;received=192.168.0.210;branch=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
Path: <sip:qBLGxQlieO at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.209:52124;rport=52124;received=192.168.0.209;branch=z9hG4bK-524287-1---f7dc3c756b6f3896
Max-Forwards: 70
Contact: <sip:6505550525 at 192.168.0.209:52124;transport=UDP;rinstance=283ff0dd3b564291>
To: <sip:6505550525 at ims.cw.4gtss.com>
From: <sip:6505550525 at ims.cw.4gtss.com>;tag=1959ab22
Call-ID: qq0DpjcQWNRPGQUHa87JrQ..
CSeq: 1 REGISTER
Expires: 6000
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
14-03-2017 13:14:26.514 UTC Debug pjutils.cpp:716: Cloned tdta0x7fb004042010 to tdta0x7fb004011510
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:1224: Remove top Route header Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
14-03-2017 13:14:26.514 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fb004011b20 => txdata 0x7fb0040115b8 mapping
14-03-2017 13:14:26.514 UTC Verbose sproutletproxy.cpp:1613: icscf-0x7fb004020750 pass initial request Request msg REGISTER/cseq=1 (tdta0x7fb004011510) to Sproutlet
14-03-2017 13:14:26.514 UTC Debug acr.cpp:1812: Create RalfACR for node type I-CSCF with role Terminating
14-03-2017 13:14:26.514 UTC Debug acr.cpp:49: Created ACR (0x7fb00408ce10)
14-03-2017 13:14:26.514 UTC Debug acr.cpp:189: Created I-CSCF Ralf ACR
14-03-2017 13:14:26.514 UTC Debug acr.cpp:269: Set record type for I-CSCF, BGCF, IBCF, AS to EVENT_RECORD
14-03-2017 13:14:26.514 UTC Debug icscfsproutlet.cpp:193: I-CSCF initialize transaction for REGISTER request
14-03-2017 13:14:26.514 UTC Debug icscfrouter.cpp:345: Perform UAR - impi 6505550525 at ims.cw.4gtss.com, impu sip:6505550525 at ims.cw.4gtss.com, vn ims.cw.4gtss.com, auth_type REG
14-03-2017 13:14:26.516 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
14-03-2017 13:14:26.516 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.516 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
14-03-2017 13:14:26.517 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
14-03-2017 13:14:26.517 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
14-03-2017 13:14:26.517 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.517 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
14-03-2017 13:14:26.517 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
14-03-2017 13:14:26.517 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
14-03-2017 13:14:26.517 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
14-03-2017 13:14:26.517 UTC Debug connection_pool.h:244: Found existing connection 0x7fb004021830 in pool
14-03-2017 13:14:26.517 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
14-03-2017 13:14:26.517 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impi/6505550525%40ims.cw.4gtss.com/registration-status?impu=sip%3A6505550525%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG (trying 192.168.0.212)
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e350
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:832: Received header content-length with value 83
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e350
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e350
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:832: Received header  with value 
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e350
14-03-2017 13:14:26.518 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc={"result-code":2001,"scscf":"sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}
14-03-2017 13:14:26.518 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
14-03-2017 13:14:26.518 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
14-03-2017 13:14:26.518 UTC Debug icscfrouter.cpp:237: HSS returned S-CSCF sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP as target
14-03-2017 13:14:26.518 UTC Debug acr.cpp:653: Storing Server-Capabilities
14-03-2017 13:14:26.518 UTC Debug icscfrouter.cpp:113: SCSCF specified by HSS: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
14-03-2017 13:14:26.518 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
14-03-2017 13:14:26.518 UTC Debug uri_classifier.cpp:204: Classified URI as 3
14-03-2017 13:14:26.519 UTC Debug icscfsproutlet.cpp:279: Found SCSCF for REGISTER
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1364: Sproutlet send_request 0x7fb004011b20
14-03-2017 13:14:26.519 UTC Verbose sproutletproxy.cpp:1400: icscf-0x7fb004020750 sending Request msg REGISTER/cseq=1 (tdta0x7fb004011510) on fork 0
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 0 responses, 1 requests, 0 timers
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1823: Processing request 0x7fb0040115b8, fork = 0
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1947: icscf-0x7fb004020750 transmitting request on fork 0
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1961: icscf-0x7fb004020750 store reference to non-ACK request Request msg REGISTER/cseq=1 (tdta0x7fb004011510) on fork 0
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fb004011b20 => txdata 0x7fb0040115b8 mapping
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
14-03-2017 13:14:26.519 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet authentication-0x7fb00408bc60 for Request msg REGISTER/cseq=1 (tdta0x7fb004011510)
14-03-2017 13:14:26.519 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=1 (tdta0x7fb004011510) (765 bytes) to downstream sproutlet authentication:
--start msg--

REGISTER sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=45333;received=192.168.0.210;branch=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
Path: <sip:qBLGxQlieO at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.209:52124;rport=52124;received=192.168.0.209;branch=z9hG4bK-524287-1---f7dc3c756b6f3896
Max-Forwards: 69
Contact: <sip:6505550525 at 192.168.0.209:52124;transport=UDP;rinstance=283ff0dd3b564291>
To: <sip:6505550525 at ims.cw.4gtss.com>
From: <sip:6505550525 at ims.cw.4gtss.com>;tag=1959ab22
Call-ID: qq0DpjcQWNRPGQUHa87JrQ..
CSeq: 1 REGISTER
Expires: 6000
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Content-Length:  0


--end msg--
14-03-2017 13:14:26.519 UTC Debug pjutils.cpp:716: Cloned tdta0x7fb004011510 to tdta0x7fb0040abd00
14-03-2017 13:14:26.519 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fb0040ac310 => txdata 0x7fb0040abda8 mapping
14-03-2017 13:14:26.519 UTC Verbose sproutletproxy.cpp:1613: authentication-0x7fb00408bc60 pass initial request Request msg REGISTER/cseq=1 (tdta0x7fb0040abd00) to Sproutlet
14-03-2017 13:14:26.519 UTC Debug authenticationsproutlet.cpp:829: Authentication module invoked
14-03-2017 13:14:26.519 UTC Debug authenticationsproutlet.cpp:841: Request needs authentication
14-03-2017 13:14:26.519 UTC Debug acr.cpp:1812: Create RalfACR for node type S-CSCF with role Originating
14-03-2017 13:14:26.519 UTC Debug acr.cpp:49: Created ACR (0x7fb004020e60)
14-03-2017 13:14:26.520 UTC Debug acr.cpp:189: Created S-CSCF Ralf ACR
14-03-2017 13:14:26.520 UTC Debug acr.cpp:229: Set record type for P/S-CSCF
14-03-2017 13:14:26.520 UTC Debug acr.cpp:237: Non-dialog message => EVENT_RECORD
14-03-2017 13:14:26.520 UTC Debug acr.cpp:1540: Stored 0 subscription identifiers
14-03-2017 13:14:26.520 UTC Debug authenticationsproutlet.cpp:1150: No authentication information in request or stale nonce, so reject with challenge
14-03-2017 13:14:26.520 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fb0040ae2d0 => txdata 0x7fb0040add68 mapping
14-03-2017 13:14:26.520 UTC Debug pjutils.cpp:423: Private identity defaulted from public identity = 6505550525 at ims.cw.4gtss.com
14-03-2017 13:14:26.520 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.520 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
14-03-2017 13:14:26.520 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
14-03-2017 13:14:26.520 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
14-03-2017 13:14:26.520 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
14-03-2017 13:14:26.520 UTC Debug connection_pool.h:244: Found existing connection 0x7fb004021830 in pool
14-03-2017 13:14:26.520 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
14-03-2017 13:14:26.520 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impi/6505550525%40ims.cw.4gtss.com/av?impu=sip%3A6505550525%40ims.cw.4gtss.com (trying 192.168.0.212)
14-03-2017 13:14:26.524 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e060
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:832: Received header content-length with value 93
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e060
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e060
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:832: Received header  with value 
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:833: Header pointer: 0x7fb020d1e060
14-03-2017 13:14:26.525 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc={"digest":{"ha1":"61ea8247adb95f7074d14b9cca86df99","realm":"ims.cw.4gtss.com","qop":"auth"}}
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
14-03-2017 13:14:26.528 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:219: Verifying AV: {"digest":{"ha1":"61ea8247adb95f7074d14b9cca86df99","realm":"ims.cw.4gtss.com","qop":"auth"}}
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:246: Digest specified
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:411: Valid AV - generate challenge
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:420: Create WWW-Authenticate header
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:536: Add Digest information
14-03-2017 13:14:26.528 UTC Debug authenticationsproutlet.cpp:591: Write authentication challenge to IMPI store
14-03-2017 13:14:26.528 UTC Debug memcachedstore.cpp:1128: Start GET from table impi for key 6505550525 at ims.cw.4gtss.com
14-03-2017 13:14:26.528 UTC Debug astaire_resolver.cpp:72: AstaireResolver::resolve for host sprout.ims.cw.4gtss.com, family 2
14-03-2017 13:14:26.528 UTC Debug utils.cpp:352: Malformed host/port sprout.ims.cw.4gtss.com
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:425: Attempt to parse sprout.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.528 UTC Verbose dnscachedresolver.cpp:486: Check cache for sprout.ims.cw.4gtss.com type 1
14-03-2017 13:14:26.528 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for sprout.ims.cw.4gtss.com A
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: BLACK
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: BLACK
14-03-2017 13:14:26.528 UTC Debug baseresolver.cpp:1032: Added an unhealthy server, now have 1 of 2
14-03-2017 13:14:26.528 UTC Debug memcachedstore.cpp:1469: Found 1 targets for sprout.ims.cw.4gtss.com
14-03-2017 13:14:26.528 UTC Debug memcachedstore.cpp:1494: Duplicate target IP=192.168.0.212, port= 11311 as it is the only target
14-03-2017 13:14:26.528 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
14-03-2017 13:14:26.528 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
14-03-2017 13:14:26.528 UTC Debug connection_pool.h:244: Found existing connection 0x7faffc00b4c0 in pool
14-03-2017 13:14:26.533 UTC Debug memcachedstore.cpp:107: Fetch result
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1093: libmemcached returned 16
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1103: Return code means the request should not be retried
14-03-2017 13:14:26.681 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1200: Key not found
14-03-2017 13:14:26.681 UTC Debug impistore.cpp:648: Storing IMPI for 6505550525 at ims.cw.4gtss.com
{"authChallenges":[{"type":"digest","nonce":"3a83e7ee39475262","nc":1,"expires":1489497306,"correlator":"z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"61ea8247adb95f7074d14b9cca86df99"}]}
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1251: Writing 231 bytes to table impi key 6505550525 at ims.cw.4gtss.com, CAS = 0, expiry = 40
14-03-2017 13:14:26.681 UTC Debug astaire_resolver.cpp:72: AstaireResolver::resolve for host sprout.ims.cw.4gtss.com, family 2
14-03-2017 13:14:26.681 UTC Debug utils.cpp:352: Malformed host/port sprout.ims.cw.4gtss.com
14-03-2017 13:14:26.681 UTC Debug baseresolver.cpp:425: Attempt to parse sprout.ims.cw.4gtss.com as IP address
14-03-2017 13:14:26.681 UTC Verbose dnscachedresolver.cpp:486: Check cache for sprout.ims.cw.4gtss.com type 1
14-03-2017 13:14:26.681 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for sprout.ims.cw.4gtss.com A
14-03-2017 13:14:26.681 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
14-03-2017 13:14:26.681 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: BLACK
14-03-2017 13:14:26.681 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: BLACK
14-03-2017 13:14:26.681 UTC Debug baseresolver.cpp:1032: Added an unhealthy server, now have 1 of 2
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1469: Found 1 targets for sprout.ims.cw.4gtss.com
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1494: Duplicate target IP=192.168.0.212, port= 11311 as it is the only target
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
14-03-2017 13:14:26.681 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
14-03-2017 13:14:26.681 UTC Debug connection_pool.h:244: Found existing connection 0x7faffc00b4c0 in pool
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:144: Attempting to add data for key impi\\6505550525 at ims.cw.4gtss.com
14-03-2017 13:14:26.681 UTC Debug memcachedstore.cpp:154: Attempting memcached ADD command
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:244: ADD/CAS returned rc = 7 (UNKNOWN READ FAILURE)
(140393823939040) UNKNOWN READ FAILURE,  host: 192.168.0.212:11311 -> libmemcached/response.cc:782
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:1093: libmemcached returned 7
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:1110: Blacklisting target
14-03-2017 13:14:26.834 UTC Debug baseresolver.cpp:400: Add 192.168.0.212:11311 transport 6 to blacklist for 30 seconds, graylist for 0 seconds
14-03-2017 13:14:26.834 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
14-03-2017 13:14:26.834 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
14-03-2017 13:14:26.834 UTC Debug connection_pool.h:244: Found existing connection 0x7faffc00b4c0 in pool
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:144: Attempting to add data for key impi\\6505550525 at ims.cw.4gtss.com
14-03-2017 13:14:26.834 UTC Debug memcachedstore.cpp:154: Attempting memcached ADD command
14-03-2017 13:14:26.986 UTC Debug memcachedstore.cpp:244: ADD/CAS returned rc = 7 (UNKNOWN READ FAILURE)
(140393823939040) UNKNOWN READ FAILURE,  host: 192.168.0.212:11311 -> libmemcached/response.cc:782
14-03-2017 13:14:26.986 UTC Debug memcachedstore.cpp:1093: libmemcached returned 7
14-03-2017 13:14:26.986 UTC Debug memcachedstore.cpp:1110: Blacklisting target
14-03-2017 13:14:26.986 UTC Debug baseresolver.cpp:400: Add 192.168.0.212:11311 transport 6 to blacklist for 30 seconds, graylist for 0 seconds
14-03-2017 13:14:26.986 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
14-03-2017 13:14:26.986 UTC Debug memcachedstore.cpp:1366: Failed to write data for impi\\6505550525 at ims.cw.4gtss.com to store with error UNKNOWN READ FAILURE
14-03-2017 13:14:26.986 UTC Error impistore.cpp:664: Failed to write IMPI for private_id 6505550525 at ims.cw.4gtss.com
14-03-2017 13:14:26.986 UTC Debug authenticationsproutlet.cpp:675: Failed to store nonce in memcached
14-03-2017 13:14:26.986 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session qq0DpjcQWNRPGQUHa87JrQ.. to - dropping!
14-03-2017 13:14:26.986 UTC Verbose sproutletproxy.cpp:1427: authentication-0x7fb00408bc60 sending Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0)
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fb0040ac310 => txdata 0x7fb0040abda8 mapping
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1504: Free message tdta0x7fb0040abd00
14-03-2017 13:14:26.986 UTC Debug pjsip: tdta0x7fb0040a Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fb0040abd00)
14-03-2017 13:14:26.986 UTC Debug acr.cpp:54: Destroyed ACR (0x7fb004020e60)
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 500
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1810: All UAC responded
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fb0040ae2d0 => txdata 0x7fb0040add68 mapping
14-03-2017 13:14:26.986 UTC Verbose sproutletproxy.cpp:2095: Routing Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0) (614 bytes) to upstream sproutlet icscf:
--start msg--

SIP/2.0 500 Internal Server Error
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=45333;received=192.168.0.210;branch=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
Via: SIP/2.0/UDP 192.168.0.209:52124;rport=52124;received=192.168.0.209;branch=z9hG4bK-524287-1---f7dc3c756b6f3896
Call-ID: qq0DpjcQWNRPGQUHa87JrQ..
From: <sip:6505550525 at ims.cw.4gtss.com>;tag=1959ab22
To: <sip:6505550525 at ims.cw.4gtss.com>;tag=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
CSeq: 1 REGISTER
WWW-Authenticate: Digest  realm="ims.cw.4gtss.com",nonce="3a83e7ee39475262",opaque="33312013558f3894",algorithm=MD5,qop="auth"
Content-Length:  0


--end msg--
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fb0040ae2d0 => txdata 0x7fb0040add68 mapping
14-03-2017 13:14:26.986 UTC Verbose sproutletproxy.cpp:1666: icscf-0x7fb004020750 received final response Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0) on fork 0, state = Terminated
14-03-2017 13:14:26.986 UTC Debug acr.cpp:1540: Stored 1 subscription identifiers
14-03-2017 13:14:26.986 UTC Debug icscfsproutlet.cpp:329: Check retry conditions for REGISTER, status = 500, S-CSCF responsive
14-03-2017 13:14:26.986 UTC Verbose sproutletproxy.cpp:1427: icscf-0x7fb004020750 sending Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0)
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 500
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1810: All UAC responded
14-03-2017 13:14:26.986 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fb0040ae2d0 => txdata 0x7fb0040add68 mapping
14-03-2017 13:14:26.986 UTC Debug pjsip: tsx0x7fb00408d Sending Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0) in state Trying
14-03-2017 13:14:26.986 UTC Verbose common_sip_processing.cpp:136: TX 614 bytes Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0) to TCP 192.168.0.210:45333:
--start msg--

SIP/2.0 500 Internal Server Error
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=45333;received=192.168.0.210;branch=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
Via: SIP/2.0/UDP 192.168.0.209:52124;rport=52124;received=192.168.0.209;branch=z9hG4bK-524287-1---f7dc3c756b6f3896
Call-ID: qq0DpjcQWNRPGQUHa87JrQ..
From: <sip:6505550525 at ims.cw.4gtss.com>;tag=1959ab22
To: <sip:6505550525 at ims.cw.4gtss.com>;tag=z9hG4bKPjxt2aG60D4lt04G2ED2a3NEeUND3o7Pwk
CSeq: 1 REGISTER
WWW-Authenticate: Digest  realm="ims.cw.4gtss.com",nonce="3a83e7ee39475262",opaque="33312013558f3894",algorithm=MD5,qop="auth"
Content-Length:  0


--end msg--
14-03-2017 13:14:26.987 UTC Debug pjsip: tsx0x7fb00408d State changed from Trying to Completed, event=TX_MSG
14-03-2017 13:14:26.987 UTC Debug basicproxy.cpp:213: tsx0x7fb00408de18 - tu_on_tsx_state UAS, TSX_STATE TX_MSG state=Completed
14-03-2017 13:14:26.987 UTC Verbose sproutletproxy.cpp:1861: icscf-0x7fb004020750 suiciding
14-03-2017 13:14:26.987 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x7fb0040214c0
14-03-2017 13:14:26.987 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session qq0DpjcQWNRPGQUHa87JrQ.. to - dropping!
14-03-2017 13:14:26.987 UTC Debug acr.cpp:54: Destroyed ACR (0x7fb00408ce10)
14-03-2017 13:14:26.987 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=1 (tdta0x7fb004042010) (tdta0x7fb004042010)
14-03-2017 13:14:26.987 UTC Verbose sproutletproxy.cpp:1861: authentication-0x7fb00408bc60 suiciding
14-03-2017 13:14:26.987 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x7fb00408b770
14-03-2017 13:14:26.987 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=1 (tdta0x7fb004011510) (tdta0x7fb004011510)
14-03-2017 13:14:26.987 UTC Debug pjsip: tdta0x7fb00401 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fb004011510)
14-03-2017 13:14:26.987 UTC Debug thread_dispatcher.cpp:200: Worker thread completed processing message 0x7fb00c0dc838
14-03-2017 13:14:26.987 UTC Debug thread_dispatcher.cpp:206: Request latency = 473226us
14-03-2017 13:14:26.993 UTC Debug pjsip: tsx0x7fb00408d Timeout timer event
14-03-2017 13:14:26.993 UTC Debug pjsip: tsx0x7fb00408d State changed from Completed to Terminated, event=TIMER
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:213: tsx0x7fb00408de18 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Terminated
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:1308: Report SAS end marker - trail (7a)
14-03-2017 13:14:26.993 UTC Debug pjsip: tsx0x7fb00408d Timeout timer event
14-03-2017 13:14:26.993 UTC Debug pjsip: tsx0x7fb00408d State changed from Terminated to Destroyed, event=TIMER
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:213: tsx0x7fb00408de18 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Destroyed
14-03-2017 13:14:26.993 UTC Debug sproutletproxy.cpp:750: tsx0x7fb00408de18 - UAS tsx destroyed
14-03-2017 13:14:26.993 UTC Debug sproutletproxy.cpp:1090: Safe for UASTsx to suicide
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:1483: Transaction ((nil)) suiciding
14-03-2017 13:14:26.993 UTC Verbose sproutletproxy.cpp:538: Sproutlet Proxy transaction (0x7fb004020bc0) destroyed
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:494: BasicProxy::UASTsx destructor (0x7fb004020bc0)
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:511: Disconnect UAC transactions from UAS transaction
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:525: Free original request
14-03-2017 13:14:26.993 UTC Debug pjsip: tdta0x7fb00404 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fb004042010)
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:534: Free un-used best response
14-03-2017 13:14:26.993 UTC Debug pjsip: tdta0x7fb00401 Destroying txdata Response msg 408/REGISTER/cseq=1 (tdta0x7fb004010500)
14-03-2017 13:14:26.993 UTC Debug basicproxy.cpp:555: BasicProxy::UASTsx destructor completed
14-03-2017 13:14:26.993 UTC Debug pjsip: tdta0x7fb0040a Destroying txdata Response msg 500/REGISTER/cseq=1 (tdta0x7fb0040adcc0)
14-03-2017 13:14:26.993 UTC Debug pjsip: tsx0x7fb00408d Transaction destroyed!

From Sebastian.Rex at metaswitch.com  Tue Mar 14 11:41:55 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Tue, 14 Mar 2017 15:41:55 +0000
Subject: [Project Clearwater] Hello
In-Reply-To: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>
References: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>
Message-ID: <SN1PR02MB16644BF41824B14985DD777F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

It looks like you're still not signed up to the mailing list. We recommend you sign up to the list by clicking the ?Mailing List Signup? link from here: http://www.projectclearwater.org/community to help your questions be answered more quickly.

From your logs, it looks like the reason that you're getting errors is that sprout is failing to contact memcached (via astaire). From the monit summary you've provided, it does look like both memcached and astaire are running, so it's not obvious what the underlying problem is here.

However, the monit summary also shows that your etcd_process is not running, which could cause all sorts of errors. Have you looked in /var/log/clearwater-etcd/clearwater-etcd.log to see what errors it's hitting? If not, I'd suggest taking a look there. If you can't see the problem, then please send us a copy of that log file and we can take a look.

It would also be good to see the contents of /var/log/astaire/astaire_current.txt and /var/log/memcached.log, as they may tell us what the issue with memcached is.

Thanks,

Seb.

-----Original Message-----
From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Ahmed Eldeeb
Sent: 14 March 2017 13:58
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] Hello

I am installing clearwater in 3 different machines and i am facing a problem when trying to register using zoiper when trying to register i received internal server error (500).

I don't know where is the problem i tired to access logs and attached it to email.


From Sebastian.Rex at metaswitch.com  Tue Mar 14 12:29:42 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Tue, 14 Mar 2017 16:29:42 +0000
Subject: [Project Clearwater] Hello
In-Reply-To: <1e68b846-1c1e-46eb-b84a-db3618fd7e45@4gtss.com>
References: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>
	<SN1PR02MB16644BF41824B14985DD777F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<1e68b846-1c1e-46eb-b84a-db3618fd7e45@4gtss.com>
Message-ID: <SN1PR02MB1664C862396BE40C3E66343C8F240@SN1PR02MB1664.namprd02.prod.outlook.com>

Hi,

Did you set up the local_config file before installing the Clearwater packages, as directed in the install instructions here: http://clearwater.readthedocs.io/en/latest/Manual_Install.html#create-the-per-node-configuration? It sounds like you've not done this, which would prevent your etcd process from starting, and hence would prevent your node configuring itself correctly.

If you've not done that, then you should create the local_config file as directed, and then restart clearwater-etcd.

Let me know if that helps,

Seb.

-----Original Message-----
From: Ahmed Eldeeb [mailto:ahmed.eldeeb at 4gtss.com] 
Sent: 14 March 2017 16:27
To: Sebastian Rex
Subject: Re: [Project Clearwater] Hello

hi seb,

When trying to restart clearwater-etcd service via terminal it shows this error
-------------------------------------------------------------------------------------------------------------------------------
  * Restarting etcd clearwater-etcd Error:  dial tcp 127.0.0.1:2379: 
getsockopt: connection refused
Must specify either etcd_cluster or etcd_proxy [fail]

--------------------------------------------------------------------------------------------------------------------------------
i dont know what is the problem with this process and how to run it correctly !!
so there isn't any logs at /var/log/clearwater-etcd/  because the service didnot started yet but there is some errors at astaire logs i have attached the log files here i hope you find where is the problem and how can i resolve it as soon as possible.

thanks in advance

On 14/03/17 17:41, Sebastian Rex wrote:
> Hi,
>
> It looks like you're still not signed up to the mailing list. We recommend you sign up to the list by clicking the ?Mailing List Signup? link from here: http://www.projectclearwater.org/community to help your questions be answered more quickly.
>
>  From your logs, it looks like the reason that you're getting errors is that sprout is failing to contact memcached (via astaire). From the monit summary you've provided, it does look like both memcached and astaire are running, so it's not obvious what the underlying problem is here.
>
> However, the monit summary also shows that your etcd_process is not running, which could cause all sorts of errors. Have you looked in /var/log/clearwater-etcd/clearwater-etcd.log to see what errors it's hitting? If not, I'd suggest taking a look there. If you can't see the problem, then please send us a copy of that log file and we can take a look.
>
> It would also be good to see the contents of /var/log/astaire/astaire_current.txt and /var/log/memcached.log, as they may tell us what the issue with memcached is.
>
> Thanks,
>
> Seb.
>
> -----Original Message-----
> From: Clearwater 
> [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of 
> Ahmed Eldeeb
> Sent: 14 March 2017 13:58
> To: clearwater at lists.projectclearwater.org
> Subject: [Project Clearwater] Hello
>
> I am installing clearwater in 3 different machines and i am facing a problem when trying to register using zoiper when trying to register i received internal server error (500).
>
> I don't know where is the problem i tired to access logs and attached it to email.
>


From Sebastian.Rex at metaswitch.com  Tue Mar 14 13:30:14 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Tue, 14 Mar 2017 17:30:14 +0000
Subject: [Project Clearwater] Hello
In-Reply-To: <f288e012-64d9-ed9a-2158-c49294e00079@4gtss.com>
References: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>
	<SN1PR02MB16644BF41824B14985DD777F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<1e68b846-1c1e-46eb-b84a-db3618fd7e45@4gtss.com>
	<SN1PR02MB1664C862396BE40C3E66343C8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<f288e012-64d9-ed9a-2158-c49294e00079@4gtss.com>
Message-ID: <SN1PR02MB1664FF7882BEDBDE115FFC6F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>

Yes, you should set the etcd_cluster to be a comma separated list of the IPs of all your nodes. However, you should only set it to this when first creating the etcd cluster. If your other nodes have successfully created the etcd cluster, then you can set the etcd_cluster to just be the IP address of any node currently in the cluster.

The interesting line from the etcd log you?ve attached is:

cannot access data directory: mkdir /var/lib/clearwater-etcd: permission denied

The clearwater-etcd directory should be owned by the ?clearwater-etcd? user, which should be the same user that runs the etcd process. If you run ?ls -al /var/lib/ | grep "clearwater-etcd?, what output do you see?

Have you tried to run clearwater-etcd manually as root at any point?

Seb.

From: Ahmed Eldeeb [mailto:ahmed.eldeeb at 4gtss.com]
Sent: 14 March 2017 16:55
To: Sebastian Rex
Subject: Re: [Project Clearwater] Hello


Hi seb,

I have created the local config file but i dont know what is the values of ips i should set in

etcd_cluster="<comma separated list of private IPs>"
i inserted the ips of my machines which are three machines ( homestead&sprout - homer&ellis - ralf&bono)

and it seems that there is some error on logs of clearwater-etcd i attached the file of log here hope you see it
On 14/03/17 18:29, Sebastian Rex wrote:

Hi,



Did you set up the local_config file before installing the Clearwater packages, as directed in the install instructions here: http://clearwater.readthedocs.io/en/latest/Manual_Install.html#create-the-per-node-configuration? It sounds like you've not done this, which would prevent your etcd process from starting, and hence would prevent your node configuring itself correctly.



If you've not done that, then you should create the local_config file as directed, and then restart clearwater-etcd.



Let me know if that helps,



Seb.



-----Original Message-----

From: Ahmed Eldeeb [mailto:ahmed.eldeeb at 4gtss.com]

Sent: 14 March 2017 16:27

To: Sebastian Rex

Subject: Re: [Project Clearwater] Hello



hi seb,



When trying to restart clearwater-etcd service via terminal it shows this error

-------------------------------------------------------------------------------------------------------------------------------

  * Restarting etcd clearwater-etcd Error:  dial tcp 127.0.0.1:2379:

getsockopt: connection refused

Must specify either etcd_cluster or etcd_proxy [fail]



--------------------------------------------------------------------------------------------------------------------------------

i dont know what is the problem with this process and how to run it correctly !!

so there isn't any logs at /var/log/clearwater-etcd/  because the service didnot started yet but there is some errors at astaire logs i have attached the log files here i hope you find where is the problem and how can i resolve it as soon as possible.



thanks in advance



On 14/03/17 17:41, Sebastian Rex wrote:

Hi,



It looks like you're still not signed up to the mailing list. We recommend you sign up to the list by clicking the ?Mailing List Signup? link from here: http://www.projectclearwater.org/community to help your questions be answered more quickly.



 From your logs, it looks like the reason that you're getting errors is that sprout is failing to contact memcached (via astaire). From the monit summary you've provided, it does look like both memcached and astaire are running, so it's not obvious what the underlying problem is here.



However, the monit summary also shows that your etcd_process is not running, which could cause all sorts of errors. Have you looked in /var/log/clearwater-etcd/clearwater-etcd.log to see what errors it's hitting? If not, I'd suggest taking a look there. If you can't see the problem, then please send us a copy of that log file and we can take a look.



It would also be good to see the contents of /var/log/astaire/astaire_current.txt and /var/log/memcached.log, as they may tell us what the issue with memcached is.



Thanks,



Seb.



-----Original Message-----

From: Clearwater

[mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of

Ahmed Eldeeb

Sent: 14 March 2017 13:58

To: clearwater at lists.projectclearwater.org<mailto:clearwater at lists.projectclearwater.org>

Subject: [Project Clearwater] Hello



I am installing clearwater in 3 different machines and i am facing a problem when trying to register using zoiper when trying to register i received internal server error (500).



I don't know where is the problem i tired to access logs and attached it to email.





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170314/6ada34cf/attachment.html>

From peter.skrzynski at nec.co.nz  Tue Mar 14 21:56:31 2017
From: peter.skrzynski at nec.co.nz (Peter Skrzynski)
Date: Wed, 15 Mar 2017 01:56:31 +0000
Subject: [Project Clearwater] Dynamic overload control.
Message-ID: <191e2330ee48407a87fd889cf4b2aea5@ex15p.necnz.internal>

Hi Clearwater,
We have some queries about the Clearwater dynamic overload control. We have had instances of SIP Request spikes which have invoked the controls, and were considering doing some load testing to verify the effect of changes to the token configuration items. However we would most appreciate some further explanation of the dynamic overload control.

The  Clearwater webpage explains that the token refresh rate is linked to the measurement of latency, and that the refresh rate rises and falls according to measured latency. However, it doesn?t say what the initial token number is, or if and how the total token number is controlled. It also doesn?t say how the token rate/number reduces back to a steady state once the load is removed.
For one ?event? that I analysed, there were 7 SIP requests in the 10 seconds beforehand (0.7/sec). In the next second there were 52 requests, 7 of which were rejected by 503 Service Unavailable. In the next second there were 60 requests of which 7 were rejected. After that the load dropped right back down, so the ?event? lasted for only 2 seconds. So that means that 45 requests were accepted in the first second, and 53 in the next second. An apparent  increase of 8 per second.
If we were able to adjust the initial number of requests handled in the first second (and not even sure if we can) say to 60, then that would ?solve? the issue for this case. But what if there were 80 requests in the first second? Do we increase it to 100? Then what if there are 120? How do we decide how many hits we should take in the all-important first second. If we make it too high, do we essentially negate the point of having overload control?
The Clearwater parameters allow you to modify the initial and maximum refresh rate, the maximum token number, and the target latency. It seems that none of these have a bearing on how many requests you can actually accept in the first second.

Are you able to clarify the operation of the overload control in terms of the ?initial second token number?, the control of the total token number, and what happens to the refresh rate and total token number once the load is removed?
Of course we do not want to rush into any changes on our system and suspect that changes are not even necessary.
Regards,
Peter.




Peter Skrzynski

Technical Sales Support
NEC New Zealand Limited
NEC House, Level 6, 40 Taranaki Street, PO Box: 1936, Wellington 6011, New Zealand
T: 043816257, M: 0274849530, F: +6443811110
peter.skrzynski at nec.co.nz<mailto:peter.skrzynski at nec.co.nz>
nz.nec.com<http://nz.nec.com>

[cid:imageed1a7a.JPG at 4ffc020f.40bf7dba]

Please consider the environment before printing this email

Attention:
The information contained in this message and or attachments is intended only for the person or entity to which it is addressed and may contain confidential and/or privileged material.  Any review, retransmission, dissemination, copying or other use of, or taking of any action in reliance upon, this information by persons or entities other than the intended recipient is prohibited. If you received this in error, please contact the sender and delete the material from any system and destroy any copies. NEC has no liability for any act or omission in reliance on the email or any attachment.  Before opening this email or any attachment(s), please check them for viruses. NEC is not responsible for any viruses in this email or any attachment(s); any changes made to this  email or any attachment(s) after they are sent; or any effects this email or any attachment(s) have on your network or computer system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170315/6b855326/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: imageed1a7a.JPG
Type: image/jpeg
Size: 14513 bytes
Desc: imageed1a7a.JPG
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170315/6b855326/attachment.jpe>

From Sebastian.Rex at metaswitch.com  Wed Mar 15 09:17:02 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Wed, 15 Mar 2017 13:17:02 +0000
Subject: [Project Clearwater] Hello
In-Reply-To: <8083dc78-e65b-862b-69e1-72b2a6829cb4@4gtss.com>
References: <7641e3e8-5387-5714-93b6-389698bd7c67@4gtss.com>
	<SN1PR02MB16644BF41824B14985DD777F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<1e68b846-1c1e-46eb-b84a-db3618fd7e45@4gtss.com>
	<SN1PR02MB1664C862396BE40C3E66343C8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<f288e012-64d9-ed9a-2158-c49294e00079@4gtss.com>
	<SN1PR02MB1664FF7882BEDBDE115FFC6F8F240@SN1PR02MB1664.namprd02.prod.outlook.com>
	<8083dc78-e65b-862b-69e1-72b2a6829cb4@4gtss.com>
Message-ID: <SN1PR02MB1664E0EDAA37248EF74AADA68F270@SN1PR02MB1664.namprd02.prod.outlook.com>

You should only include your Project Clearwater nodes, not your DNS server.

Seb.

From: Ahmed Eldeeb [mailto:ahmed.eldeeb at 4gtss.com]
Sent: 15 March 2017 12:40
To: Sebastian Rex
Subject: Re: [Project Clearwater] Hello


hi seb,

Ok in my deployment i created 3 virtual machines for the 6 nodes in addition to a DNS server where the three machines are connected. i want to know should i add the DNS server IP to the IPs set in etcd_cluster in local_config file or i have to set the IPs of three machines only ?

On 14/03/17 19:30, Sebastian Rex wrote:
ls -al /var/lib/ | grep "clearwater-etcd

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170315/0dad4fd4/attachment.html>

From ahmed.eldeeb at 4gtss.com  Tue Mar 21 06:23:49 2017
From: ahmed.eldeeb at 4gtss.com (Ahmed Eldeeb)
Date: Tue, 21 Mar 2017 12:23:49 +0200
Subject: [Project Clearwater] 403 forbidden on registering
Message-ID: <db135de9-2355-a2da-1da4-18181445cfb7@4gtss.com>

I have a problem while registering using zoiper on my phone i received 
403 forbidden from homestead node whenever i try to register however
All nodes are running normally
The user name is exist at ellis node database and in the homestead_cache 
tables beside the logs of homestead which shows no errors in the logs, i 
have attached the logs of homestead and sprout and hope you find a solution.

Thanks in advance.
-------------- next part --------------
IMSSubscription xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CxDataType.xsd"><PrivateID>Unspecified</PrivateID><ServiceProfile><InitialFilterCriteria><TriggerPoint><ConditionTypeCNF>0</ConditionTypeCNF><SPT><ConditionNegated>0</ConditionNegated><Group>0</Group><Method>INVITE</Method><Extension /></SPT></TriggerPoint><ApplicationServer><ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName><DefaultHandling>0</DefaultHandling></ApplicationServer></InitialFilterCriteria><PublicIdentity><Identity>sip:6505550579 at ims.cw.4gtss.com</Identity></PublicIdentity></ServiceProfile></IMSSubscription>
21-03-2017 09:13:19.217 UTC Debug cache.cpp:438: Found stored XML for subscriber, treating as UNREGISTERED state
21-03-2017 09:13:19.217 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:19.217 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:19.217 UTC Debug handlers.cpp:1200: Got IMS subscription from cache
21-03-2017 09:13:19.217 UTC Debug handlers.cpp:1215: TTL for this database record is 0, IMS Subscription XML is not empty, registration state is UNREGISTERED, and the charging addresses are empty
21-03-2017 09:13:19.217 UTC Debug handlers.cpp:1241: Subscriber registering with new binding
21-03-2017 09:13:19.217 UTC Debug handlers.cpp:1475: Handling authentication failure/timeout
21-03-2017 09:13:19.217 UTC Debug handlers.cpp:1522: Sending 200 response (body was {"reqtype": "dereg-auth-timeout", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"})
21-03-2017 09:13:19.217 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com



-----------------------------------------------------------------------------------------------------------------





21-03-2017 09:13:23.449 UTC Verbose httpstack.cpp:345: Process request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:23.449 UTC Debug handlers.cpp:1133: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, server name sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 09:13:23.449 UTC Debug handlers.cpp:1057: Determining request type from '{"reqtype": "dereg-auth-timeout", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}'
21-03-2017 09:13:23.449 UTC Debug handlers.cpp:1101: New value of _type is 7
21-03-2017 09:13:23.449 UTC Debug handlers.cpp:1171: Try to find IMS Subscription information in the cache
21-03-2017 09:13:23.449 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:23.449 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:23.449 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:23.449 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:23.449 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:23.449 UTC Debug cassandra_store.cpp:159: Generated Cassandra timestamp 1490087603449392
21-03-2017 09:13:23.449 UTC Debug cache.cpp:350: Issuing get for key sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:23.450 UTC Debug cassandra_store.cpp:731: Failed TWO read for get_row. Try ONE
21-03-2017 09:13:23.452 UTC Debug cache.cpp:370: Retrieved XML column with TTL 0 and value <?xml version='1.0' encoding='UTF-8'?>
<IMSSubscription xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CxDataType.xsd"><PrivateID>Unspecified</PrivateID><ServiceProfile><InitialFilterCriteria><TriggerPoint><ConditionTypeCNF>0</ConditionTypeCNF><SPT><ConditionNegated>0</ConditionNegated><Group>0</Group><Method>INVITE</Method><Extension /></SPT></TriggerPoint><ApplicationServer><ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName><DefaultHandling>0</DefaultHandling></ApplicationServer></InitialFilterCriteria><PublicIdentity><Identity>sip:6505550579 at ims.cw.4gtss.com</Identity></PublicIdentity></ServiceProfile></IMSSubscription>
21-03-2017 09:13:23.452 UTC Debug cache.cpp:438: Found stored XML for subscriber, treating as UNREGISTERED state
21-03-2017 09:13:23.452 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:23.453 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:23.453 UTC Debug handlers.cpp:1200: Got IMS subscription from cache
21-03-2017 09:13:23.453 UTC Debug handlers.cpp:1215: TTL for this database record is 0, IMS Subscription XML is not empty, registration state is UNREGISTERED, and the charging addresses are empty
21-03-2017 09:13:23.453 UTC Debug handlers.cpp:1241: Subscriber registering with new binding
21-03-2017 09:13:23.453 UTC Debug handlers.cpp:1475: Handling authentication failure/timeout
21-03-2017 09:13:23.453 UTC Debug handlers.cpp:1522: Sending 200 response (body was {"reqtype": "dereg-auth-timeout", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"})
21-03-2017 09:13:23.453 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com



--------------------------------------------------------------------------------------------------





21-03-2017 09:13:30.852 UTC Verbose httpstack.cpp:345: Process request for URL /ping, args (null)
21-03-2017 09:13:30.852 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /ping, args (null)

21-03-2017 09:13:31.569 UTC Verbose httpstack.cpp:345: Process request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:31.569 UTC Debug handlers.cpp:1133: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, server name sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 09:13:31.569 UTC Debug handlers.cpp:1057: Determining request type from '{"reqtype": "dereg-auth-timeout", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}'
21-03-2017 09:13:31.569 UTC Debug handlers.cpp:1101: New value of _type is 7
21-03-2017 09:13:31.569 UTC Debug handlers.cpp:1171: Try to find IMS Subscription information in the cache
21-03-2017 09:13:31.569 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:31.569 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:31.569 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:31.569 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:31.569 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:31.570 UTC Debug cassandra_store.cpp:159: Generated Cassandra timestamp 1490087611570002
21-03-2017 09:13:31.570 UTC Debug cache.cpp:350: Issuing get for key sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:31.570 UTC Debug cassandra_store.cpp:731: Failed TWO read for get_row. Try ONE
21-03-2017 09:13:31.573 UTC Debug cache.cpp:370: Retrieved XML column with TTL 0 and value <?xml version='1.0' encoding='UTF-8'?>
<IMSSubscription xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CxDataType.xsd"><PrivateID>Unspecified</PrivateID><ServiceProfile><InitialFilterCriteria><TriggerPoint><ConditionTypeCNF>0</ConditionTypeCNF><SPT><ConditionNegated>0</ConditionNegated><Group>0</Group><Method>INVITE</Method><Extension /></SPT></TriggerPoint><ApplicationServer><ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName><DefaultHandling>0</DefaultHandling></ApplicationServer></InitialFilterCriteria><PublicIdentity><Identity>sip:6505550579 at ims.cw.4gtss.com</Identity></PublicIdentity></ServiceProfile></IMSSubscription>
21-03-2017 09:13:31.573 UTC Debug cache.cpp:438: Found stored XML for subscriber, treating as UNREGISTERED state
21-03-2017 09:13:31.573 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:31.573 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:31.573 UTC Debug handlers.cpp:1200: Got IMS subscription from cache
21-03-2017 09:13:31.573 UTC Debug handlers.cpp:1215: TTL for this database record is 0, IMS Subscription XML is not empty, registration state is UNREGISTERED, and the charging addresses are empty
21-03-2017 09:13:31.573 UTC Debug handlers.cpp:1241: Subscriber registering with new binding
21-03-2017 09:13:31.573 UTC Debug handlers.cpp:1475: Handling authentication failure/timeout
21-03-2017 09:13:31.573 UTC Debug handlers.cpp:1522: Sending 200 response (body was {"reqtype": "dereg-auth-timeout", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"})
21-03-2017 09:13:31.573 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com



----------------------------------------------------------------------------------------------------------







21-03-2017 09:13:36.303 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:36.303 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
21-03-2017 09:13:36.303 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:36.303 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/av, args impu=sip%3A6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:36.303 UTC Debug handlers.cpp:155: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, scheme Unknown, authorization 
21-03-2017 09:13:36.303 UTC Debug handlers.cpp:181: Querying cache for authentication vector for 6505550579 at ims.cw.4gtss.com/sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:36.303 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:36.303 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:36.303 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:36.303 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:36.303 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:36.303 UTC Debug cache.cpp:673: Looking for authentication vector for 6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:36.303 UTC Debug cache.cpp:685: Checking public ID sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:36.303 UTC Debug cache.cpp:695: Issuing cache query
21-03-2017 09:13:36.304 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
21-03-2017 09:13:36.305 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:36.305 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:36.305 UTC Debug communicationmonitor.cpp:82: Checking communication changes - successful attempts 6, failures 0
21-03-2017 09:13:36.305 UTC Debug handlers.cpp:201: Got authentication vector with digest f9490a60de145aed870afb6facbc1894 from cache
21-03-2017 09:13:36.305 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/av, args impu=sip%3A6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:36.325 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:36.325 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
21-03-2017 09:13:36.325 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:36.326 UTC Verbose httpstack.cpp:345: Process request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:36.326 UTC Debug handlers.cpp:1133: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, server name sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 09:13:36.326 UTC Debug handlers.cpp:1057: Determining request type from '{"reqtype": "dereg-auth-failed", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}'
21-03-2017 09:13:36.326 UTC Debug handlers.cpp:1101: New value of _type is 6
21-03-2017 09:13:36.326 UTC Debug handlers.cpp:1171: Try to find IMS Subscription information in the cache
21-03-2017 09:13:36.326 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:36.326 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:36.326 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:36.326 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:36.326 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:36.326 UTC Debug cassandra_store.cpp:159: Generated Cassandra timestamp 1490087616326224
21-03-2017 09:13:36.326 UTC Debug cache.cpp:350: Issuing get for key sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:36.326 UTC Debug cassandra_store.cpp:731: Failed TWO read for get_row. Try ONE
21-03-2017 09:13:36.327 UTC Debug cache.cpp:370: Retrieved XML column with TTL 0 and value <?xml version='1.0' encoding='UTF-8'?>
<IMSSubscription xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CxDataType.xsd"><PrivateID>Unspecified</PrivateID><ServiceProfile><InitialFilterCriteria><TriggerPoint><ConditionTypeCNF>0</ConditionTypeCNF><SPT><ConditionNegated>0</ConditionNegated><Group>0</Group><Method>INVITE</Method><Extension /></SPT></TriggerPoint><ApplicationServer><ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName><DefaultHandling>0</DefaultHandling></ApplicationServer></InitialFilterCriteria><PublicIdentity><Identity>sip:6505550579 at ims.cw.4gtss.com</Identity></PublicIdentity></ServiceProfile></IMSSubscription>
21-03-2017 09:13:36.327 UTC Debug cache.cpp:438: Found stored XML for subscriber, treating as UNREGISTERED state
21-03-2017 09:13:36.327 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:36.327 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:36.327 UTC Debug handlers.cpp:1200: Got IMS subscription from cache
21-03-2017 09:13:36.327 UTC Debug handlers.cpp:1215: TTL for this database record is 0, IMS Subscription XML is not empty, registration state is UNREGISTERED, and the charging addresses are empty
21-03-2017 09:13:36.327 UTC Debug handlers.cpp:1241: Subscriber registering with new binding
21-03-2017 09:13:36.327 UTC Debug handlers.cpp:1475: Handling authentication failure/timeout
21-03-2017 09:13:36.327 UTC Debug handlers.cpp:1522: Sending 200 response (body was {"reqtype": "dereg-auth-failed", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"})
21-03-2017 09:13:36.327 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com







-------------------------------------------------------------------------------------------------






21-03-2017 09:13:40.259 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:40.259 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
21-03-2017 09:13:40.259 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:40.261 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/av, args impu=sip%3A6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:40.261 UTC Debug handlers.cpp:155: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, scheme Unknown, authorization 
21-03-2017 09:13:40.261 UTC Debug handlers.cpp:181: Querying cache for authentication vector for 6505550579 at ims.cw.4gtss.com/sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:40.261 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:40.261 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:40.261 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:40.261 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:40.261 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:40.261 UTC Debug cache.cpp:673: Looking for authentication vector for 6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:40.261 UTC Debug cache.cpp:685: Checking public ID sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:40.261 UTC Debug cache.cpp:695: Issuing cache query
21-03-2017 09:13:40.262 UTC Debug cassandra_store.cpp:700: Failed TWO read for get_columns. Try ONE
21-03-2017 09:13:40.264 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:40.264 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:40.264 UTC Debug handlers.cpp:201: Got authentication vector with digest f9490a60de145aed870afb6facbc1894 from cache
21-03-2017 09:13:40.264 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/av, args impu=sip%3A6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:40.291 UTC Verbose httpstack.cpp:345: Process request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:40.291 UTC Debug handlers.cpp:647: No HSS configured - fake response if subscriber exists
21-03-2017 09:13:40.291 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impi/6505550579%40ims.cw.4gtss.com/registration-status, args impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG
21-03-2017 09:13:40.292 UTC Verbose httpstack.cpp:345: Process request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com
21-03-2017 09:13:40.292 UTC Debug handlers.cpp:1133: Parsed HTTP request: private ID 6505550579 at ims.cw.4gtss.com, public ID sip:6505550579 at ims.cw.4gtss.com, server name sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 09:13:40.292 UTC Debug handlers.cpp:1057: Determining request type from '{"reqtype": "dereg-auth-failed", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}'
21-03-2017 09:13:40.292 UTC Debug handlers.cpp:1101: New value of _type is 6
21-03-2017 09:13:40.292 UTC Debug handlers.cpp:1171: Try to find IMS Subscription information in the cache
21-03-2017 09:13:40.292 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 9160, family 2
21-03-2017 09:13:40.292 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 09:13:40.292 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 09:13:40.292 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 9160
21-03-2017 09:13:40.292 UTC Debug connection_pool.h:244: Found existing connection 0x25ef330 in pool
21-03-2017 09:13:40.292 UTC Debug cassandra_store.cpp:159: Generated Cassandra timestamp 1490087620292910
21-03-2017 09:13:40.292 UTC Debug cache.cpp:350: Issuing get for key sip:6505550579 at ims.cw.4gtss.com
21-03-2017 09:13:40.293 UTC Debug cassandra_store.cpp:731: Failed TWO read for get_row. Try ONE
21-03-2017 09:13:40.294 UTC Debug cache.cpp:370: Retrieved XML column with TTL 0 and value <?xml version='1.0' encoding='UTF-8'?>
<IMSSubscription xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="CxDataType.xsd"><PrivateID>Unspecified</PrivateID><ServiceProfile><InitialFilterCriteria><TriggerPoint><ConditionTypeCNF>0</ConditionTypeCNF><SPT><ConditionNegated>0</ConditionNegated><Group>0</Group><Method>INVITE</Method><Extension /></SPT></TriggerPoint><ApplicationServer><ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName><DefaultHandling>0</DefaultHandling></ApplicationServer></InitialFilterCriteria><PublicIdentity><Identity>sip:6505550579 at ims.cw.4gtss.com</Identity></PublicIdentity></ServiceProfile></IMSSubscription>
21-03-2017 09:13:40.294 UTC Debug cache.cpp:438: Found stored XML for subscriber, treating as UNREGISTERED state
21-03-2017 09:13:40.294 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:9160 transport 6
21-03-2017 09:13:40.294 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 9160 to pool
21-03-2017 09:13:40.294 UTC Debug handlers.cpp:1200: Got IMS subscription from cache
21-03-2017 09:13:40.294 UTC Debug handlers.cpp:1215: TTL for this database record is 0, IMS Subscription XML is not empty, registration state is UNREGISTERED, and the charging addresses are empty
21-03-2017 09:13:40.294 UTC Debug handlers.cpp:1241: Subscriber registering with new binding
21-03-2017 09:13:40.294 UTC Debug handlers.cpp:1475: Handling authentication failure/timeout
21-03-2017 09:13:40.294 UTC Debug handlers.cpp:1522: Sending 200 response (body was {"reqtype": "dereg-auth-failed", "server_name": "sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"})
21-03-2017 09:13:40.294 UTC Verbose httpstack.cpp:93: Sending response 200 to request for URL /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data, args private_id=6505550579%40ims.cw.4gtss.com

-------------- next part --------------
Monit 5.18.1 uptime: 49m

Process 'sprout_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1392
  parent pid                   1
  uid                          997
  effective uid                997
  gid                          997
  uptime                       48m
  threads                      148
  children                     0
  cpu                          0.6%
  cpu total                    0.6%
  memory                       0.6% [12.0 MB]
  memory total                 0.6% [12.0 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'sprout_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'poll_sprout_sip'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'poll_sprout_http'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'snmpd_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1685
  parent pid                   1
  uid                          119
  effective uid                119
  gid                          129
  uptime                       48m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [3.0 MB]
  memory total                 0.1% [3.0 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'ntp_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          2297
  parent pid                   1
  uid                          118
  effective uid                118
  gid                          128
  uptime                       48m
  threads                      1
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.1% [2.0 MB]
  memory total                 0.1% [2.0 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

System 'node-machine'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  load average                 [0.38] [0.14] [0.18]
  cpu                          2.7%us 2.3%sy 1.8%wa
  memory usage                 1.7 GB [85.7%]
  swap usage                   282.5 MB [27.6%]
  uptime                       50m
  boot time                    Tue, 21 Mar 2017 09:26:43
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'nginx_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1708
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       48m
  threads                      1
  children                     4
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.0% [624 kB]
  memory total                 0.2% [4.0 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'nginx_ping'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                                                Dload  Upload   Total   Spent    Left  Speed
                                 0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'nginx_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'monit_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'memcached_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3304
  parent pid                   1
  uid                          120
  effective uid                120
  gid                          130
  uptime                       48m
  threads                      6
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.4% [7.9 MB]
  memory total                 0.4% [7.9 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'memcached_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'poll_memcached'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'homestead_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          4143
  parent pid                   1
  uid                          991
  effective uid                991
  gid                          991
  uptime                       47m
  threads                      121
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       1.2% [24.6 MB]
  memory total                 1.2% [24.6 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'homestead_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'poll_homestead'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'check_cx_health'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              1
  last output                  Traceback (most recent call last):
                                 File "/usr/share/clearwater/bin/check_cx_health.py", line 64, in <module>
                                   import netsnmp
                               ImportError: No module named netsnmp
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'homestead-prov_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3622
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       47m
  threads                      6
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       1.9% [37.7 MB]
  memory total                 1.9% [37.7 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'poll_homestead-prov'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'clearwater_queue_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3490
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       48m
  threads                      10
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.6% [11.2 MB]
  memory total                 0.6% [11.2 MB]
  data collected               Tue, 21 Mar 2017 10:16:14

Program 'clearwater_queue_manager_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:14

Process 'etcd_process'
  status                       Execution failed | Does not exist
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'etcd_uptime'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 21 Mar 2017 09:29:11

Program 'poll_etcd_cluster'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 21 Mar 2017 09:29:11

Program 'poll_etcd'
  status                       Wait parent
  monitoring status            Wait parent
  monitoring mode              active
  on reboot                    start
  data collected               Tue, 21 Mar 2017 09:29:11

Process 'clearwater_diags_monitor_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          1630
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       48m
  threads                      1
  children                     1
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.0% [516 kB]
  memory total                 0.0% [516 kB]
  data collected               Tue, 21 Mar 2017 10:16:45

Process 'clearwater_config_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3186
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       48m
  threads                      8
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.5% [9.4 MB]
  memory total                 0.5% [9.4 MB]
  data collected               Tue, 21 Mar 2017 10:16:45

Process 'clearwater_cluster_manager_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3120
  parent pid                   1
  uid                          0
  effective uid                0
  gid                          0
  uptime                       48m
  threads                      5
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.2% [4.6 MB]
  memory total                 0.2% [4.6 MB]
  data collected               Tue, 21 Mar 2017 10:16:45

Process 'cassandra_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3177
  parent pid                   1
  uid                          121
  effective uid                121
  gid                          131
  uptime                       48m
  threads                      86
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       68.8% [1.3 GB]
  memory total                 68.8% [1.3 GB]
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'cassandra_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'poll_cassandra'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'poll_cqlsh'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:45

Process 'chronos_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3672
  parent pid                   1
  uid                          993
  effective uid                993
  gid                          993
  uptime                       47m
  threads                      235
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       1.0% [20.2 MB]
  memory total                 1.0% [20.2 MB]
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'chronos_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'poll_chronos'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  -
  data collected               Tue, 21 Mar 2017 10:16:45

Process 'astaire_process'
  status                       Running
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  pid                          3089
  parent pid                   1
  uid                          996
  effective uid                996
  gid                          996
  uptime                       48m
  threads                      20
  children                     0
  cpu                          0.0%
  cpu total                    0.0%
  memory                       0.2% [4.2 MB]
  memory total                 0.2% [4.2 MB]
  data collected               Tue, 21 Mar 2017 10:16:45

Program 'astaire_uptime'
  status                       Status ok
  monitoring status            Monitored
  monitoring mode              active
  on reboot                    start
  last exit value              0
  last output                  zmq_msg_recv: Resource temporarily unavailable
  data collected               Tue, 21 Mar 2017 10:16:45

-------------- next part --------------
21-03-2017 08:22:33.431 UTC Verbose sproutletproxy.cpp:538: Sproutlet Proxy transaction (0x7fee48010aa0) destroyed
21-03-2017 08:22:33.431 UTC Debug basicproxy.cpp:494: BasicProxy::UASTsx destructor (0x7fee48010aa0)
21-03-2017 08:22:33.431 UTC Debug basicproxy.cpp:511: Disconnect UAC transactions from UAS transaction
21-03-2017 08:22:33.431 UTC Debug basicproxy.cpp:525: Free original request
21-03-2017 08:22:33.431 UTC Debug pjsip: tdta0x7fee4803 Destroying txdata Request msg REGISTER/cseq=2 (tdta0x7fee4803f080)
21-03-2017 08:22:33.431 UTC Debug basicproxy.cpp:534: Free un-used best response
21-03-2017 08:22:33.431 UTC Debug pjsip: tdta0x7fee4800 Destroying txdata Response msg 408/REGISTER/cseq=2 (tdta0x7fee4800b4d0)
21-03-2017 08:22:33.431 UTC Debug basicproxy.cpp:555: BasicProxy::UASTsx destructor completed
21-03-2017 08:22:33.431 UTC Debug pjsip: tdta0x7fee4806 Destroying txdata Response msg 403/REGISTER/cseq=2 (tdta0x7fee48062180)
21-03-2017 08:22:33.431 UTC Debug pjsip: tsx0x7fee4802f Transaction destroyed!









21-03-2017 08:22:36.387 UTC Debug pjsip: sip_endpoint.c Processing incoming message: Request msg REGISTER/cseq=1 (rdata0x7fee1408b790)
21-03-2017 08:22:36.387 UTC Verbose common_sip_processing.cpp:120: RX 792 bytes Request msg REGISTER/cseq=1 (rdata0x7fee1408b790) from TCP 192.168.0.210:60414:
--start msg--

REGISTER sip:ims.cw.4gtss.com:5060;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport;branch=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---e90943a4cef07621
Max-Forwards: 70
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 1 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
21-03-2017 08:22:36.388 UTC Debug pjutils.cpp:1689: Logging SAS Call-ID marker, Call-ID HnR-9wnGh4KD9zJ059lKvw..
21-03-2017 08:22:36.388 UTC Debug thread_dispatcher.cpp:264: Queuing cloned received message 0x7fee14078ee8 for worker threads
21-03-2017 08:22:36.388 UTC Debug thread_dispatcher.cpp:150: Worker thread dequeue message 0x7fee14078ee8
21-03-2017 08:22:36.388 UTC Debug pjsip: sip_endpoint.c Distributing rdata to modules: Request msg REGISTER/cseq=1 (rdata0x7fee14078ee8)
21-03-2017 08:22:36.388 UTC Debug uri_classifier.cpp:174: home domain: true, local_to_node: false, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
21-03-2017 08:22:36.388 UTC Debug uri_classifier.cpp:204: Classified URI as 4
21-03-2017 08:22:36.388 UTC Debug basicproxy.cpp:92: Process REGISTER request
21-03-2017 08:22:36.388 UTC Verbose sproutletproxy.cpp:507: Sproutlet Proxy transaction (0x7fee5005a0c0) created
21-03-2017 08:22:36.388 UTC Debug basicproxy.cpp:1298: Report SAS start marker - trail (183)
21-03-2017 08:22:36.389 UTC Debug pjutils.cpp:699: Cloned Request msg REGISTER/cseq=1 (rdata0x7fee14078ee8) to tdta0x7fee50026b90
21-03-2017 08:22:36.389 UTC Debug pjsip: tsx0x7fee5002a Transaction created for Request msg REGISTER/cseq=1 (rdata0x7fee14078ee8)
21-03-2017 08:22:36.389 UTC Debug pjsip: tsx0x7fee5002a Incoming Request msg REGISTER/cseq=1 (rdata0x7fee14078ee8) in state Null
21-03-2017 08:22:36.389 UTC Debug pjsip: tsx0x7fee5002a State changed from Null to Trying, event=RX_MSG
21-03-2017 08:22:36.389 UTC Debug basicproxy.cpp:213: tsx0x7fee5002a948 - tu_on_tsx_state UAS, TSX_STATE RX_MSG state=Trying
21-03-2017 08:22:36.389 UTC Debug pjsip:       endpoint Response msg 408/REGISTER/cseq=1 (tdta0x7fee50029260) created
21-03-2017 08:22:36.389 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
21-03-2017 08:22:36.389 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig
21-03-2017 08:22:36.389 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.389 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.389 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.390 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet icscf-0x7fee50059fb0 for Request msg REGISTER/cseq=1 (tdta0x7fee50026b90)
21-03-2017 08:22:36.390 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=1 (tdta0x7fee50026b90) (821 bytes) to downstream sproutlet icscf:
--start msg--

REGISTER sip:ims.cw.4gtss.com:5060;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60414;received=192.168.0.210;branch=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---e90943a4cef07621
Max-Forwards: 70
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 1 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
21-03-2017 08:22:36.390 UTC Debug pjutils.cpp:716: Cloned tdta0x7fee50026b90 to tdta0x7fee50018000
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:1224: Remove top Route header Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
21-03-2017 08:22:36.390 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fee50018610 => txdata 0x7fee500180a8 mapping
21-03-2017 08:22:36.390 UTC Verbose sproutletproxy.cpp:1613: icscf-0x7fee50059fb0 pass initial request Request msg REGISTER/cseq=1 (tdta0x7fee50018000) to Sproutlet
21-03-2017 08:22:36.390 UTC Debug acr.cpp:1812: Create RalfACR for node type I-CSCF with role Terminating
21-03-2017 08:22:36.390 UTC Debug acr.cpp:49: Created ACR (0x7fee5002a270)
21-03-2017 08:22:36.390 UTC Debug acr.cpp:189: Created I-CSCF Ralf ACR
21-03-2017 08:22:36.390 UTC Debug acr.cpp:269: Set record type for I-CSCF, BGCF, IBCF, AS to EVENT_RECORD
21-03-2017 08:22:36.390 UTC Debug icscfsproutlet.cpp:193: I-CSCF initialize transaction for REGISTER request
21-03-2017 08:22:36.390 UTC Debug icscfrouter.cpp:345: Perform UAR - impi 6505550579 at ims.cw.4gtss.com, impu sip:6505550579 at ims.cw.4gtss.com, vn ims.cw.4gtss.com, auth_type REG
21-03-2017 08:22:36.391 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.391 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.391 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.391 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
21-03-2017 08:22:36.391 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
21-03-2017 08:22:36.391 UTC Debug connection_pool.h:244: Found existing connection 0x7fee04023ac0 in pool
21-03-2017 08:22:36.391 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
21-03-2017 08:22:36.391 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impi/6505550579%40ims.cw.4gtss.com/registration-status?impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG (trying 192.168.0.212)
21-03-2017 08:22:36.391 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
21-03-2017 08:22:36.391 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1350
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:832: Received header content-length with value 83
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1350
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1350
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:832: Received header  with value 
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1350
21-03-2017 08:22:36.392 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc={"result-code":2001,"scscf":"sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}
21-03-2017 08:22:36.392 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
21-03-2017 08:22:36.392 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
21-03-2017 08:22:36.392 UTC Debug icscfrouter.cpp:237: HSS returned S-CSCF sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP as target
21-03-2017 08:22:36.392 UTC Debug acr.cpp:653: Storing Server-Capabilities
21-03-2017 08:22:36.392 UTC Debug icscfrouter.cpp:113: SCSCF specified by HSS: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 08:22:36.392 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
21-03-2017 08:22:36.392 UTC Debug uri_classifier.cpp:204: Classified URI as 3
21-03-2017 08:22:36.392 UTC Debug icscfsproutlet.cpp:279: Found SCSCF for REGISTER
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1364: Sproutlet send_request 0x7fee50018610
21-03-2017 08:22:36.392 UTC Verbose sproutletproxy.cpp:1400: icscf-0x7fee50059fb0 sending Request msg REGISTER/cseq=1 (tdta0x7fee50018000) on fork 0
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 0 responses, 1 requests, 0 timers
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1823: Processing request 0x7fee500180a8, fork = 0
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1947: icscf-0x7fee50059fb0 transmitting request on fork 0
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1961: icscf-0x7fee50059fb0 store reference to non-ACK request Request msg REGISTER/cseq=1 (tdta0x7fee50018000) on fork 0
21-03-2017 08:22:36.392 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fee50018610 => txdata 0x7fee500180a8 mapping
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
21-03-2017 08:22:36.393 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet authentication-0x7fee5005a990 for Request msg REGISTER/cseq=1 (tdta0x7fee50018000)
21-03-2017 08:22:36.393 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=1 (tdta0x7fee50018000) (763 bytes) to downstream sproutlet authentication:
--start msg--

REGISTER sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60414;received=192.168.0.210;branch=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---e90943a4cef07621
Max-Forwards: 69
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 1 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Content-Length:  0


--end msg--
21-03-2017 08:22:36.393 UTC Debug pjutils.cpp:716: Cloned tdta0x7fee50018000 to tdta0x7fee500616a0
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fee50061cb0 => txdata 0x7fee50061748 mapping
21-03-2017 08:22:36.393 UTC Verbose sproutletproxy.cpp:1613: authentication-0x7fee5005a990 pass initial request Request msg REGISTER/cseq=1 (tdta0x7fee500616a0) to Sproutlet
21-03-2017 08:22:36.393 UTC Debug authenticationsproutlet.cpp:829: Authentication module invoked
21-03-2017 08:22:36.393 UTC Debug authenticationsproutlet.cpp:841: Request needs authentication
21-03-2017 08:22:36.393 UTC Debug acr.cpp:1812: Create RalfACR for node type S-CSCF with role Originating
21-03-2017 08:22:36.393 UTC Debug acr.cpp:49: Created ACR (0x7fee50019c20)
21-03-2017 08:22:36.393 UTC Debug acr.cpp:189: Created S-CSCF Ralf ACR
21-03-2017 08:22:36.393 UTC Debug acr.cpp:229: Set record type for P/S-CSCF
21-03-2017 08:22:36.393 UTC Debug acr.cpp:237: Non-dialog message => EVENT_RECORD
21-03-2017 08:22:36.393 UTC Debug acr.cpp:1540: Stored 0 subscription identifiers
21-03-2017 08:22:36.393 UTC Debug authenticationsproutlet.cpp:1150: No authentication information in request or stale nonce, so reject with challenge
21-03-2017 08:22:36.393 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fee50063c70 => txdata 0x7fee50063708 mapping
21-03-2017 08:22:36.393 UTC Debug pjutils.cpp:423: Private identity defaulted from public identity = 6505550579 at ims.cw.4gtss.com
21-03-2017 08:22:36.393 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
21-03-2017 08:22:36.393 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.393 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.393 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
21-03-2017 08:22:36.393 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.394 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.394 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.394 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.394 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
21-03-2017 08:22:36.394 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
21-03-2017 08:22:36.394 UTC Debug connection_pool.h:244: Found existing connection 0x7fee04023ac0 in pool
21-03-2017 08:22:36.394 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
21-03-2017 08:22:36.394 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impi/6505550579%40ims.cw.4gtss.com/av?impu=sip%3A6505550579%40ims.cw.4gtss.com (trying 192.168.0.212)
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1060
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:832: Received header content-length with value 93
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1060
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1060
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:832: Received header  with value 
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1060
21-03-2017 08:22:36.397 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc={"digest":{"ha1":"f9490a60de145aed870afb6facbc1894","realm":"ims.cw.4gtss.com","qop":"auth"}}
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
21-03-2017 08:22:36.398 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:219: Verifying AV: {"digest":{"ha1":"f9490a60de145aed870afb6facbc1894","realm":"ims.cw.4gtss.com","qop":"auth"}}
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:246: Digest specified
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:411: Valid AV - generate challenge
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:420: Create WWW-Authenticate header
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:536: Add Digest information
21-03-2017 08:22:36.398 UTC Debug authenticationsproutlet.cpp:591: Write authentication challenge to IMPI store
21-03-2017 08:22:36.398 UTC Debug memcachedstore.cpp:1128: Start GET from table impi for key 6505550579 at ims.cw.4gtss.com
21-03-2017 08:22:36.398 UTC Debug astaire_resolver.cpp:72: AstaireResolver::resolve for host sprout.ims.cw.4gtss.com, family 2
21-03-2017 08:22:36.398 UTC Debug utils.cpp:352: Malformed host/port sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:425: Attempt to parse sprout.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.398 UTC Verbose dnscachedresolver.cpp:486: Check cache for sprout.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.398 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for sprout.ims.cw.4gtss.com A
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.398 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 2
21-03-2017 08:22:36.398 UTC Debug memcachedstore.cpp:1469: Found 1 targets for sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.398 UTC Debug memcachedstore.cpp:1494: Duplicate target IP=192.168.0.212, port= 11311 as it is the only target
21-03-2017 08:22:36.398 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
21-03-2017 08:22:36.398 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
21-03-2017 08:22:36.398 UTC Debug connection_pool.h:244: Found existing connection 0x7fee0403fb90 in pool
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:107: Fetch result
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:115: Found record on replica
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1093: libmemcached returned 0
21-03-2017 08:22:36.399 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1172: Read 442 bytes from table impi key 6505550579 at ims.cw.4gtss.com, CAS = 104
21-03-2017 08:22:36.399 UTC Debug impistore.cpp:783: Retrieved IMPI for 6505550579 at ims.cw.4gtss.com
{"authChallenges":[{"type":"digest","nonce":"7651f6915ec1a1a3","nc":1,"expires":1490084591,"correlator":"z9hG4bKPjt.RUpwKN0ZmRpvwMT1uo0uP7E2.k3mmT","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"},{"type":"digest","nonce":"3f0f42671ad0e902","nc":1,"expires":1490084593,"correlator":"z9hG4bKPj2AIRW02l3PcY2jz.sbXZd5wO-0TIRhDK","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"}]}
21-03-2017 08:22:36.399 UTC Debug impistore.cpp:648: Storing IMPI for 6505550579 at ims.cw.4gtss.com
{"authChallenges":[{"type":"digest","nonce":"7651f6915ec1a1a3","nc":1,"expires":1490084591,"correlator":"z9hG4bKPjt.RUpwKN0ZmRpvwMT1uo0uP7E2.k3mmT","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"},{"type":"digest","nonce":"3f0f42671ad0e902","nc":1,"expires":1490084593,"correlator":"z9hG4bKPj2AIRW02l3PcY2jz.sbXZd5wO-0TIRhDK","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"},{"type":"digest","nonce":"74aa750f213c9ee2","nc":1,"expires":1490084596,"correlator":"z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"}]}
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1251: Writing 653 bytes to table impi key 6505550579 at ims.cw.4gtss.com, CAS = 104, expiry = 40
21-03-2017 08:22:36.399 UTC Debug astaire_resolver.cpp:72: AstaireResolver::resolve for host sprout.ims.cw.4gtss.com, family 2
21-03-2017 08:22:36.399 UTC Debug utils.cpp:352: Malformed host/port sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.399 UTC Debug baseresolver.cpp:425: Attempt to parse sprout.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.399 UTC Verbose dnscachedresolver.cpp:486: Check cache for sprout.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.399 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for sprout.ims.cw.4gtss.com A
21-03-2017 08:22:36.399 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.399 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.399 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.399 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 2
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1469: Found 1 targets for sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1494: Duplicate target IP=192.168.0.212, port= 11311 as it is the only target
21-03-2017 08:22:36.399 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
21-03-2017 08:22:36.399 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
21-03-2017 08:22:36.399 UTC Debug connection_pool.h:244: Found existing connection 0x7fee0403fb90 in pool
21-03-2017 08:22:36.403 UTC Debug memcachedstore.cpp:1093: libmemcached returned 0
21-03-2017 08:22:36.403 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
21-03-2017 08:22:36.403 UTC Debug memcachedstore.cpp:1328: Write successful
21-03-2017 08:22:36.403 UTC Debug authenticationsproutlet.cpp:663: Sending {"impi": "6505550579 at ims.cw.4gtss.com", "impu": "sip:6505550579 at ims.cw.4gtss.com", "nonce": "74aa750f213c9ee2"} to Chronos to set AV timer
21-03-2017 08:22:36.403 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host 127.0.0.1, port 7253, family 2
21-03-2017 08:22:36.403 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 08:22:36.403 UTC Debug a_record_resolver.cpp:88: Target is an IP address
21-03-2017 08:22:36.403 UTC Debug baseresolver.cpp:425: Attempt to parse 127.0.0.1 as IP address
21-03-2017 08:22:36.403 UTC Debug connection_pool.h:231: Request for connection to IP: 127.0.0.1, port: 7253
21-03-2017 08:22:36.403 UTC Debug connection_pool.h:244: Found existing connection 0x7fee0406a370 in pool
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:505: Sending HTTP request : http://127.0.0.1:7253/timers (trying 127.0.0.1)
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1540
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:832: Received header location with value /timers/000cc83863f00067-2
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1540
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:832: Received header content-length with value 0
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1540
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:832: Received header  with value 
21-03-2017 08:22:36.403 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee217c1540
21-03-2017 08:22:36.404 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc=
21-03-2017 08:22:36.404 UTC Debug baseresolver.cpp:830: Successful response from  127.0.0.1:7253 transport 6
21-03-2017 08:22:36.404 UTC Debug connection_pool.h:267: Release connection to IP: 127.0.0.1, port: 7253 to pool
21-03-2017 08:22:36.404 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session HnR-9wnGh4KD9zJ059lKvw.. to - dropping!
21-03-2017 08:22:36.404 UTC Verbose sproutletproxy.cpp:1427: authentication-0x7fee5005a990 sending Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660)
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fee50061cb0 => txdata 0x7fee50061748 mapping
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1504: Free message tdta0x7fee500616a0
21-03-2017 08:22:36.404 UTC Debug pjsip: tdta0x7fee5006 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fee500616a0)
21-03-2017 08:22:36.404 UTC Debug acr.cpp:54: Destroyed ACR (0x7fee50019c20)
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 401
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1810: All UAC responded
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fee50063c70 => txdata 0x7fee50063708 mapping
21-03-2017 08:22:36.404 UTC Verbose sproutletproxy.cpp:2095: Routing Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660) (605 bytes) to upstream sproutlet icscf:
--start msg--

SIP/2.0 401 Unauthorized
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60414;received=192.168.0.210;branch=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---e90943a4cef07621
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
To: <sip:6505550579 at ims.cw.4gtss.com>;tag=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
CSeq: 1 REGISTER
WWW-Authenticate: Digest  realm="ims.cw.4gtss.com",nonce="74aa750f213c9ee2",opaque="6672d0ba0d7b3b36",algorithm=MD5,qop="auth"
Content-Length:  0


--end msg--
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1768: Adding message 0x7fee50063c70 => txdata 0x7fee50063708 mapping
21-03-2017 08:22:36.404 UTC Verbose sproutletproxy.cpp:1666: icscf-0x7fee50059fb0 received final response Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660) on fork 0, state = Terminated
21-03-2017 08:22:36.404 UTC Debug acr.cpp:1540: Stored 1 subscription identifiers
21-03-2017 08:22:36.404 UTC Debug icscfsproutlet.cpp:329: Check retry conditions for REGISTER, status = 401, S-CSCF responsive
21-03-2017 08:22:36.404 UTC Verbose sproutletproxy.cpp:1427: icscf-0x7fee50059fb0 sending Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660)
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 401
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1810: All UAC responded
21-03-2017 08:22:36.404 UTC Debug sproutletproxy.cpp:1775: Removing message 0x7fee50063c70 => txdata 0x7fee50063708 mapping
21-03-2017 08:22:36.404 UTC Debug pjsip: tsx0x7fee5002a Sending Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660) in state Trying
21-03-2017 08:22:36.404 UTC Verbose common_sip_processing.cpp:136: TX 605 bytes Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660) to TCP 192.168.0.210:60414:
--start msg--

SIP/2.0 401 Unauthorized
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60414;received=192.168.0.210;branch=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---e90943a4cef07621
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
To: <sip:6505550579 at ims.cw.4gtss.com>;tag=z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv
CSeq: 1 REGISTER
WWW-Authenticate: Digest  realm="ims.cw.4gtss.com",nonce="74aa750f213c9ee2",opaque="6672d0ba0d7b3b36",algorithm=MD5,qop="auth"
Content-Length:  0


--end msg--
21-03-2017 08:22:36.409 UTC Debug pjsip: tsx0x7fee5002a State changed from Trying to Completed, event=TX_MSG
21-03-2017 08:22:36.409 UTC Debug basicproxy.cpp:213: tsx0x7fee5002a948 - tu_on_tsx_state UAS, TSX_STATE TX_MSG state=Completed
21-03-2017 08:22:36.409 UTC Verbose sproutletproxy.cpp:1861: icscf-0x7fee50059fb0 suiciding
21-03-2017 08:22:36.409 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x7fee50059e80
21-03-2017 08:22:36.409 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session HnR-9wnGh4KD9zJ059lKvw.. to - dropping!
21-03-2017 08:22:36.409 UTC Debug acr.cpp:54: Destroyed ACR (0x7fee5002a270)
21-03-2017 08:22:36.409 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=1 (tdta0x7fee50026b90) (tdta0x7fee50026b90)
21-03-2017 08:22:36.409 UTC Verbose sproutletproxy.cpp:1861: authentication-0x7fee5005a990 suiciding
21-03-2017 08:22:36.409 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x7fee50019440
21-03-2017 08:22:36.409 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=1 (tdta0x7fee50018000) (tdta0x7fee50018000)
21-03-2017 08:22:36.409 UTC Debug pjsip: tdta0x7fee5001 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fee50018000)
21-03-2017 08:22:36.409 UTC Debug thread_dispatcher.cpp:200: Worker thread completed processing message 0x7fee14078ee8
21-03-2017 08:22:36.409 UTC Debug thread_dispatcher.cpp:206: Request latency = 21665us
21-03-2017 08:22:36.419 UTC Debug pjsip: sip_endpoint.c Processing incoming message: Request msg REGISTER/cseq=2 (rdata0x7fee1403bad0)
21-03-2017 08:22:36.420 UTC Verbose common_sip_processing.cpp:120: RX 1143 bytes Request msg REGISTER/cseq=2 (rdata0x7fee1403bad0) from TCP 192.168.0.210:60955:
--start msg--

REGISTER sip:ims.cw.4gtss.com:5060;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport;branch=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---a84d41eebb19eac6
Max-Forwards: 70
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 2 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Authorization: Digest response="1af58947279ff5b6675f966e26754b8e", username="6505550579 at ims.cw.4gtss.com", realm="ims.cw.4gtss.com", nonce="74aa750f213c9ee2", uri="sip:ims.cw.4gtss.com:5060;transport=UDP", algorithm=MD5, cnonce="ab4a76c4cdfc6a814c214b2a6c26bb13", opaque="6672d0ba0d7b3b36", qop=auth, nc=00000001,integrity-protected=ip-assoc-pending
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
21-03-2017 08:22:36.420 UTC Debug pjutils.cpp:1689: Logging SAS Call-ID marker, Call-ID HnR-9wnGh4KD9zJ059lKvw..
21-03-2017 08:22:36.420 UTC Debug thread_dispatcher.cpp:264: Queuing cloned received message 0x7fee14078ee8 for worker threads
21-03-2017 08:22:36.420 UTC Debug thread_dispatcher.cpp:150: Worker thread dequeue message 0x7fee14078ee8
21-03-2017 08:22:36.420 UTC Debug pjsip: sip_endpoint.c Distributing rdata to modules: Request msg REGISTER/cseq=2 (rdata0x7fee14078ee8)
21-03-2017 08:22:36.420 UTC Debug uri_classifier.cpp:174: home domain: true, local_to_node: false, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
21-03-2017 08:22:36.420 UTC Debug uri_classifier.cpp:204: Classified URI as 4
21-03-2017 08:22:36.420 UTC Debug basicproxy.cpp:92: Process REGISTER request
21-03-2017 08:22:36.420 UTC Verbose sproutletproxy.cpp:507: Sproutlet Proxy transaction (0x36e3b40) created
21-03-2017 08:22:36.420 UTC Debug basicproxy.cpp:1298: Report SAS start marker - trail (184)
21-03-2017 08:22:36.420 UTC Debug pjutils.cpp:699: Cloned Request msg REGISTER/cseq=2 (rdata0x7fee14078ee8) to tdta0x3724020
21-03-2017 08:22:36.420 UTC Debug pjsip:   tsx0x36e48f8 Transaction created for Request msg REGISTER/cseq=2 (rdata0x7fee14078ee8)
21-03-2017 08:22:36.420 UTC Debug pjsip:   tsx0x36e48f8 Incoming Request msg REGISTER/cseq=2 (rdata0x7fee14078ee8) in state Null
21-03-2017 08:22:36.420 UTC Debug pjsip:   tsx0x36e48f8 State changed from Null to Trying, event=RX_MSG
21-03-2017 08:22:36.420 UTC Debug basicproxy.cpp:213: tsx0x36e48f8 - tu_on_tsx_state UAS, TSX_STATE RX_MSG state=Trying
21-03-2017 08:22:36.420 UTC Debug pjsip:       endpoint Response msg 408/REGISTER/cseq=2 (tdta0x36dd4f0) created
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:289: Possible service name icscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:293: Adding possible service name icscf based on domain
21-03-2017 08:22:36.420 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet icscf-0x2726120 for Request msg REGISTER/cseq=2 (tdta0x3724020)
21-03-2017 08:22:36.420 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=2 (tdta0x3724020) (1172 bytes) to downstream sproutlet icscf:
--start msg--

REGISTER sip:ims.cw.4gtss.com:5060;transport=UDP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60955;received=192.168.0.210;branch=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---a84d41eebb19eac6
Max-Forwards: 70
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 2 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Authorization: Digest response="1af58947279ff5b6675f966e26754b8e", username="6505550579 at ims.cw.4gtss.com", realm="ims.cw.4gtss.com", nonce="74aa750f213c9ee2", uri="sip:ims.cw.4gtss.com:5060;transport=UDP", algorithm=MD5, cnonce="ab4a76c4cdfc6a814c214b2a6c26bb13", opaque="6672d0ba0d7b3b36", qop=auth, nc=00000001,integrity-protected=ip-assoc-pending
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
Content-Length:  0


--end msg--
21-03-2017 08:22:36.420 UTC Debug pjutils.cpp:716: Cloned tdta0x3724020 to tdta0x3741fc0
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:1224: Remove top Route header Route: <sip:icscf.sprout.ims.cw.4gtss.com:5052;transport=TCP;lr;orig>
21-03-2017 08:22:36.420 UTC Debug sproutletproxy.cpp:1768: Adding message 0x37425d0 => txdata 0x3742068 mapping
21-03-2017 08:22:36.420 UTC Verbose sproutletproxy.cpp:1613: icscf-0x2726120 pass initial request Request msg REGISTER/cseq=2 (tdta0x3741fc0) to Sproutlet
21-03-2017 08:22:36.420 UTC Debug acr.cpp:1812: Create RalfACR for node type I-CSCF with role Terminating
21-03-2017 08:22:36.420 UTC Debug acr.cpp:49: Created ACR (0x36e0ac0)
21-03-2017 08:22:36.420 UTC Debug acr.cpp:189: Created I-CSCF Ralf ACR
21-03-2017 08:22:36.420 UTC Debug acr.cpp:269: Set record type for I-CSCF, BGCF, IBCF, AS to EVENT_RECORD
21-03-2017 08:22:36.420 UTC Debug icscfsproutlet.cpp:193: I-CSCF initialize transaction for REGISTER request
21-03-2017 08:22:36.421 UTC Debug icscfrouter.cpp:345: Perform UAR - impi 6505550579 at ims.cw.4gtss.com, impu sip:6505550579 at ims.cw.4gtss.com, vn ims.cw.4gtss.com, auth_type REG
21-03-2017 08:22:36.421 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.421 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.421 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.421 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
21-03-2017 08:22:36.421 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
21-03-2017 08:22:36.421 UTC Debug connection_pool.h:244: Found existing connection 0x7fee04023ac0 in pool
21-03-2017 08:22:36.425 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
21-03-2017 08:22:36.425 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impi/6505550579%40ims.cw.4gtss.com/registration-status?impu=sip%3A6505550579%40ims.cw.4gtss.com&visited-network=ims.cw.4gtss.com&auth-type=REG (trying 192.168.0.212)
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0350
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:832: Received header content-length with value 83
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0350
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0350
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:832: Received header  with value 
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0350
21-03-2017 08:22:36.426 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc={"result-code":2001,"scscf":"sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP"}
21-03-2017 08:22:36.426 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
21-03-2017 08:22:36.426 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
21-03-2017 08:22:36.426 UTC Debug icscfrouter.cpp:237: HSS returned S-CSCF sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP as target
21-03-2017 08:22:36.426 UTC Debug acr.cpp:653: Storing Server-Capabilities
21-03-2017 08:22:36.426 UTC Debug icscfrouter.cpp:113: SCSCF specified by HSS: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 08:22:36.426 UTC Debug uri_classifier.cpp:174: home domain: false, local_to_node: true, is_gruu: false, enforce_user_phone: false, prefer_sip: true, treat_number_as_phone: false
21-03-2017 08:22:36.426 UTC Debug uri_classifier.cpp:204: Classified URI as 3
21-03-2017 08:22:36.426 UTC Debug icscfsproutlet.cpp:279: Found SCSCF for REGISTER
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1364: Sproutlet send_request 0x37425d0
21-03-2017 08:22:36.426 UTC Verbose sproutletproxy.cpp:1400: icscf-0x2726120 sending Request msg REGISTER/cseq=2 (tdta0x3741fc0) on fork 0
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 0 responses, 1 requests, 0 timers
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1823: Processing request 0x3742068, fork = 0
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1947: icscf-0x2726120 transmitting request on fork 0
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1961: icscf-0x2726120 store reference to non-ACK request Request msg REGISTER/cseq=2 (tdta0x3741fc0) on fork 0
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1775: Removing message 0x37425d0 => txdata 0x3742068 mapping
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:119: Find target Sproutlet for request
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:154: Found next routable URI: sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:289: Possible service name scscf will be used if sprout.ims.cw.4gtss.com is a local hostname
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:293: Adding possible service name scscf based on domain
21-03-2017 08:22:36.426 UTC Verbose sproutletproxy.cpp:1163: Created Sproutlet authentication-0x36e5590 for Request msg REGISTER/cseq=2 (tdta0x3741fc0)
21-03-2017 08:22:36.426 UTC Verbose sproutletproxy.cpp:2095: Routing Request msg REGISTER/cseq=2 (tdta0x3741fc0) (1114 bytes) to downstream sproutlet authentication:
--start msg--

REGISTER sip:scscf.sprout.ims.cw.4gtss.com:5054;transport=TCP SIP/2.0
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60955;received=192.168.0.210;branch=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
Path: <sip:Eo4svm1ALS at 192.168.0.210:5058;transport=TCP;lr;ob>
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---a84d41eebb19eac6
Max-Forwards: 69
Contact: <sip:6505550579 at 192.168.0.240:48520;transport=UDP;rinstance=a86ac72e2fe2b65c>
To: <sip:6505550579 at ims.cw.4gtss.com>
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
CSeq: 2 REGISTER
Expires: 60
User-Agent: Zoiper rv2.8.30
Authorization: Digest response="1af58947279ff5b6675f966e26754b8e", username="6505550579 at ims.cw.4gtss.com", realm="ims.cw.4gtss.com", nonce="74aa750f213c9ee2", uri="sip:ims.cw.4gtss.com:5060;transport=UDP", algorithm=MD5, cnonce="ab4a76c4cdfc6a814c214b2a6c26bb13", opaque="6672d0ba0d7b3b36", qop=auth, nc=00000001,integrity-protected=ip-assoc-pending
Allow-Events: presence, kpml, talk
P-Visited-Network-ID: ims.cw.4gtss.com
Content-Length:  0


--end msg--
21-03-2017 08:22:36.426 UTC Debug pjutils.cpp:716: Cloned tdta0x3741fc0 to tdta0x36efd70
21-03-2017 08:22:36.426 UTC Debug sproutletproxy.cpp:1768: Adding message 0x36f0380 => txdata 0x36efe18 mapping
21-03-2017 08:22:36.426 UTC Verbose sproutletproxy.cpp:1613: authentication-0x36e5590 pass initial request Request msg REGISTER/cseq=2 (tdta0x36efd70) to Sproutlet
21-03-2017 08:22:36.427 UTC Debug authenticationsproutlet.cpp:829: Authentication module invoked
21-03-2017 08:22:36.427 UTC Debug authenticationsproutlet.cpp:748: Authorization header in request
21-03-2017 08:22:36.427 UTC Debug authenticationsproutlet.cpp:756: Integrity protected with ip-assoc-pending
21-03-2017 08:22:36.427 UTC Debug authenticationsproutlet.cpp:841: Request needs authentication
21-03-2017 08:22:36.427 UTC Debug memcachedstore.cpp:1128: Start GET from table impi for key 6505550579 at ims.cw.4gtss.com
21-03-2017 08:22:36.427 UTC Debug astaire_resolver.cpp:72: AstaireResolver::resolve for host sprout.ims.cw.4gtss.com, family 2
21-03-2017 08:22:36.427 UTC Debug utils.cpp:352: Malformed host/port sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.427 UTC Debug baseresolver.cpp:425: Attempt to parse sprout.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.427 UTC Verbose dnscachedresolver.cpp:486: Check cache for sprout.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.427 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for sprout.ims.cw.4gtss.com A
21-03-2017 08:22:36.427 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.427 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.427 UTC Debug baseresolver.cpp:819: 192.168.0.212:11311 transport 6 has state: WHITE
21-03-2017 08:22:36.427 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 2
21-03-2017 08:22:36.427 UTC Debug memcachedstore.cpp:1469: Found 1 targets for sprout.ims.cw.4gtss.com
21-03-2017 08:22:36.427 UTC Debug memcachedstore.cpp:1494: Duplicate target IP=192.168.0.212, port= 11311 as it is the only target
21-03-2017 08:22:36.427 UTC Debug memcachedstore.cpp:1082: Try server IP 192.168.0.212, port 11311
21-03-2017 08:22:36.427 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 11311
21-03-2017 08:22:36.427 UTC Debug connection_pool.h:244: Found existing connection 0x7fee0403fb90 in pool
21-03-2017 08:22:36.428 UTC Debug memcachedstore.cpp:107: Fetch result
21-03-2017 08:22:36.428 UTC Debug memcachedstore.cpp:115: Found record on replica
21-03-2017 08:22:36.428 UTC Debug memcachedstore.cpp:1093: libmemcached returned 0
21-03-2017 08:22:36.428 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 11311 to pool
21-03-2017 08:22:36.428 UTC Debug memcachedstore.cpp:1172: Read 653 bytes from table impi key 6505550579 at ims.cw.4gtss.com, CAS = 105
21-03-2017 08:22:36.428 UTC Debug impistore.cpp:783: Retrieved IMPI for 6505550579 at ims.cw.4gtss.com
{"authChallenges":[{"type":"digest","nonce":"7651f6915ec1a1a3","nc":1,"expires":1490084591,"correlator":"z9hG4bKPjt.RUpwKN0ZmRpvwMT1uo0uP7E2.k3mmT","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"},{"type":"digest","nonce":"3f0f42671ad0e902","nc":1,"expires":1490084593,"correlator":"z9hG4bKPj2AIRW02l3PcY2jz.sbXZd5wO-0TIRhDK","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"},{"type":"digest","nonce":"74aa750f213c9ee2","nc":1,"expires":1490084596,"correlator":"z9hG4bKPjIDVhvlY1flniuKKiX46I4TY4BGhG04bv","realm":"ims.cw.4gtss.com","qop":"auth","ha1":"f9490a60de145aed870afb6facbc1894"}]}
21-03-2017 08:22:36.428 UTC Debug authenticationsproutlet.cpp:961: Verify authentication information in request
21-03-2017 08:22:36.428 UTC Debug authenticationsproutlet.cpp:343: Found Digest HA1 = f9490a60de145aed870afb6facbc1894
21-03-2017 08:22:36.428 UTC Debug acr.cpp:1812: Create RalfACR for node type S-CSCF with role Originating
21-03-2017 08:22:36.428 UTC Debug acr.cpp:49: Created ACR (0x3702a70)
21-03-2017 08:22:36.428 UTC Debug acr.cpp:189: Created S-CSCF Ralf ACR
21-03-2017 08:22:36.428 UTC Debug acr.cpp:229: Set record type for P/S-CSCF
21-03-2017 08:22:36.428 UTC Debug acr.cpp:237: Non-dialog message => EVENT_RECORD
21-03-2017 08:22:36.428 UTC Debug acr.cpp:1540: Stored 0 subscription identifiers
21-03-2017 08:22:36.428 UTC Error authenticationsproutlet.cpp:1168: Authentication failed, Invalid authorization digest (PJSIP_EAUTHINVALIDDIGEST)
21-03-2017 08:22:36.428 UTC Debug pjutils.cpp:417: Private identity from authorization header = 6505550579 at ims.cw.4gtss.com
21-03-2017 08:22:36.428 UTC Debug hssconnection.cpp:614: Making Homestead request for /impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data?private_id=6505550579%40ims.cw.4gtss.com
21-03-2017 08:22:36.428 UTC Debug a_record_resolver.cpp:80: ARecordResolver::resolve_iter for host hs.ims.cw.4gtss.com, port 8888, family 2
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.428 UTC Verbose dnscachedresolver.cpp:486: Check cache for hs.ims.cw.4gtss.com type 1
21-03-2017 08:22:36.428 UTC Debug dnscachedresolver.cpp:588: Pulling 1 records from cache for hs.ims.cw.4gtss.com A
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:366: Found 1 A/AAAA records, creating iterator
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:425: Attempt to parse hs.ims.cw.4gtss.com as IP address
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:819: 192.168.0.212:8888 transport 6 has state: WHITE
21-03-2017 08:22:36.428 UTC Debug baseresolver.cpp:1004: Added a whitelisted server, now have 1 of 1
21-03-2017 08:22:36.428 UTC Debug connection_pool.h:231: Request for connection to IP: 192.168.0.212, port: 8888
21-03-2017 08:22:36.428 UTC Debug connection_pool.h:244: Found existing connection 0x7fee04023ac0 in pool
21-03-2017 08:22:36.428 UTC Debug httpclient.cpp:478: Set CURLOPT_RESOLVE: hs.ims.cw.4gtss.com:8888:192.168.0.212
21-03-2017 08:22:36.428 UTC Debug httpclient.cpp:505: Sending HTTP request : http://hs.ims.cw.4gtss.com:8888/impu/sip%3A6505550579%40ims.cw.4gtss.com/reg-data?private_id=6505550579%40ims.cw.4gtss.com (trying 192.168.0.212)
21-03-2017 08:22:36.430 UTC Debug pjsip: tsx0x7fee5002a Timeout timer event
21-03-2017 08:22:36.430 UTC Debug pjsip: tsx0x7fee5002a State changed from Completed to Terminated, event=TIMER
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:213: tsx0x7fee5002a948 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Terminated
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:1308: Report SAS end marker - trail (183)
21-03-2017 08:22:36.430 UTC Debug pjsip: tsx0x7fee5002a Timeout timer event
21-03-2017 08:22:36.430 UTC Debug pjsip: tsx0x7fee5002a State changed from Terminated to Destroyed, event=TIMER
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:213: tsx0x7fee5002a948 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Destroyed
21-03-2017 08:22:36.430 UTC Debug sproutletproxy.cpp:750: tsx0x7fee5002a948 - UAS tsx destroyed
21-03-2017 08:22:36.430 UTC Debug sproutletproxy.cpp:1090: Safe for UASTsx to suicide
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:1483: Transaction ((nil)) suiciding
21-03-2017 08:22:36.430 UTC Verbose sproutletproxy.cpp:538: Sproutlet Proxy transaction (0x7fee5005a0c0) destroyed
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:494: BasicProxy::UASTsx destructor (0x7fee5005a0c0)
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:511: Disconnect UAC transactions from UAS transaction
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:525: Free original request
21-03-2017 08:22:36.430 UTC Debug pjsip: tdta0x7fee5002 Destroying txdata Request msg REGISTER/cseq=1 (tdta0x7fee50026b90)
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:534: Free un-used best response
21-03-2017 08:22:36.430 UTC Debug pjsip: tdta0x7fee5002 Destroying txdata Response msg 408/REGISTER/cseq=1 (tdta0x7fee50029260)
21-03-2017 08:22:36.430 UTC Debug basicproxy.cpp:555: BasicProxy::UASTsx destructor completed
21-03-2017 08:22:36.430 UTC Debug pjsip: tdta0x7fee5006 Destroying txdata Response msg 401/REGISTER/cseq=1 (tdta0x7fee50063660)
21-03-2017 08:22:36.430 UTC Debug pjsip: tsx0x7fee5002a Transaction destroyed!
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:832: Received header http/1.1200ok with value 
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0540
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:832: Received header content-length with value 825
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0540
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:832: Received header content-type with value text/plain
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0540
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:832: Received header  with value 
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:833: Header pointer: 0x7fee20fc0540
21-03-2017 08:22:36.430 UTC Debug httpclient.cpp:538: Received HTTP response: status=200, doc=<ClearwaterRegData>
	<RegistrationState>UNREGISTERED</RegistrationState>
	<IMSSubscription xsi="http://www.w3.org/2001/XMLSchema-instance" noNamespaceSchemaLocation="CxDataType.xsd">
		<PrivateID>Unspecified</PrivateID>
		<ServiceProfile>
			<InitialFilterCriteria>
				<TriggerPoint>
					<ConditionTypeCNF>0</ConditionTypeCNF>
					<SPT>
						<ConditionNegated>0</ConditionNegated>
						<Group>0</Group>
						<Method>INVITE</Method>
						<Extension/>
					</SPT>
				</TriggerPoint>
				<ApplicationServer>
					<ServerName>sip:mmtel.ims.cw.4gtss.com</ServerName>
					<DefaultHandling>0</DefaultHandling>
				</ApplicationServer>
			</InitialFilterCriteria>
			<PublicIdentity>
				<Identity>sip:6505550579 at ims.cw.4gtss.com</Identity>
			</PublicIdentity>
		</ServiceProfile>
	</IMSSubscription>
</ClearwaterRegData>


21-03-2017 08:22:36.430 UTC Debug baseresolver.cpp:830: Successful response from  192.168.0.212:8888 transport 6
21-03-2017 08:22:36.430 UTC Debug connection_pool.h:267: Release connection to IP: 192.168.0.212, port: 8888 to pool
21-03-2017 08:22:36.430 UTC Debug hssconnection.cpp:372: Processing Identity node from HSS XML - sip:6505550579 at ims.cw.4gtss.com

21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1768: Adding message 0x3747820 => txdata 0x37472b8 mapping
21-03-2017 08:22:36.431 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session HnR-9wnGh4KD9zJ059lKvw.. to - dropping!
21-03-2017 08:22:36.431 UTC Verbose sproutletproxy.cpp:1427: authentication-0x36e5590 sending Response msg 403/REGISTER/cseq=2 (tdta0x3747210)
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1775: Removing message 0x36f0380 => txdata 0x36efe18 mapping
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1504: Free message tdta0x36efd70
21-03-2017 08:22:36.431 UTC Debug pjsip:  tdta0x36efd70 Destroying txdata Request msg REGISTER/cseq=2 (tdta0x36efd70)
21-03-2017 08:22:36.431 UTC Debug acr.cpp:54: Destroyed ACR (0x3702a70)
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 403
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1810: All UAC responded
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1775: Removing message 0x3747820 => txdata 0x37472b8 mapping
21-03-2017 08:22:36.431 UTC Verbose sproutletproxy.cpp:2095: Routing Response msg 403/REGISTER/cseq=2 (tdta0x3747210) (474 bytes) to upstream sproutlet icscf:
--start msg--

SIP/2.0 403 Forbidden
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60955;received=192.168.0.210;branch=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---a84d41eebb19eac6
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
To: <sip:6505550579 at ims.cw.4gtss.com>;tag=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
CSeq: 2 REGISTER
Content-Length:  0


--end msg--
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1768: Adding message 0x3747820 => txdata 0x37472b8 mapping
21-03-2017 08:22:36.431 UTC Verbose sproutletproxy.cpp:1666: icscf-0x2726120 received final response Response msg 403/REGISTER/cseq=2 (tdta0x3747210) on fork 0, state = Terminated
21-03-2017 08:22:36.431 UTC Debug acr.cpp:1540: Stored 1 subscription identifiers
21-03-2017 08:22:36.431 UTC Debug icscfsproutlet.cpp:329: Check retry conditions for REGISTER, status = 403, S-CSCF responsive
21-03-2017 08:22:36.431 UTC Verbose sproutletproxy.cpp:1427: icscf-0x2726120 sending Response msg 403/REGISTER/cseq=2 (tdta0x3747210)
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1783: Processing actions from sproutlet - 1 responses, 0 requests, 0 timers
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1869: Aggregating response with status code 403
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1919: 3xx/4xx/5xx/6xx response
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1923: Best 3xx/4xx/5xx/6xx response so far
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1810: All UAC responded
21-03-2017 08:22:36.431 UTC Debug sproutletproxy.cpp:1775: Removing message 0x3747820 => txdata 0x37472b8 mapping
21-03-2017 08:22:36.431 UTC Debug pjsip:   tsx0x36e48f8 Sending Response msg 403/REGISTER/cseq=2 (tdta0x3747210) in state Trying
21-03-2017 08:22:36.431 UTC Verbose common_sip_processing.cpp:136: TX 474 bytes Response msg 403/REGISTER/cseq=2 (tdta0x3747210) to TCP 192.168.0.210:60955:
--start msg--

SIP/2.0 403 Forbidden
Via: SIP/2.0/TCP 192.168.0.210:5058;rport=60955;received=192.168.0.210;branch=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
Via: SIP/2.0/UDP 192.168.0.240:48520;rport=48520;received=192.168.0.240;branch=z9hG4bK-524287-1---a84d41eebb19eac6
Call-ID: HnR-9wnGh4KD9zJ059lKvw..
From: <sip:6505550579 at ims.cw.4gtss.com>;tag=c84a675a
To: <sip:6505550579 at ims.cw.4gtss.com>;tag=z9hG4bKPjS7rvJDhkmLD17J-SlQqWj9JY7WZyM0xm
CSeq: 2 REGISTER
Content-Length:  0


--end msg--
21-03-2017 08:22:36.436 UTC Debug pjsip:   tsx0x36e48f8 State changed from Trying to Completed, event=TX_MSG
21-03-2017 08:22:36.436 UTC Debug basicproxy.cpp:213: tsx0x36e48f8 - tu_on_tsx_state UAS, TSX_STATE TX_MSG state=Completed
21-03-2017 08:22:36.436 UTC Verbose sproutletproxy.cpp:1861: icscf-0x2726120 suiciding
21-03-2017 08:22:36.436 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x2725fc0
21-03-2017 08:22:36.436 UTC Info acr.cpp:690: No CCF or ECF to send ACR for session HnR-9wnGh4KD9zJ059lKvw.. to - dropping!
21-03-2017 08:22:36.436 UTC Debug acr.cpp:54: Destroyed ACR (0x36e0ac0)
21-03-2017 08:22:36.436 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=2 (tdta0x3724020) (tdta0x3724020)
21-03-2017 08:22:36.436 UTC Verbose sproutletproxy.cpp:1861: authentication-0x36e5590 suiciding
21-03-2017 08:22:36.436 UTC Debug sproutletproxy.cpp:1169: Destroying SproutletWrapper 0x36e5230
21-03-2017 08:22:36.436 UTC Debug sproutletproxy.cpp:1178: Free original request Request msg REGISTER/cseq=2 (tdta0x3741fc0) (tdta0x3741fc0)
21-03-2017 08:22:36.436 UTC Debug pjsip:  tdta0x3741fc0 Destroying txdata Request msg REGISTER/cseq=2 (tdta0x3741fc0)
21-03-2017 08:22:36.436 UTC Debug thread_dispatcher.cpp:200: Worker thread completed processing message 0x7fee14078ee8
21-03-2017 08:22:36.436 UTC Debug thread_dispatcher.cpp:206: Request latency = 16533us
21-03-2017 08:22:36.440 UTC Debug pjsip:   tsx0x36e48f8 Timeout timer event
21-03-2017 08:22:36.440 UTC Debug pjsip:   tsx0x36e48f8 State changed from Completed to Terminated, event=TIMER
21-03-2017 08:22:36.440 UTC Debug basicproxy.cpp:213: tsx0x36e48f8 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Terminated
21-03-2017 08:22:36.440 UTC Debug basicproxy.cpp:1308: Report SAS end marker - trail (184)
21-03-2017 08:22:36.440 UTC Debug pjsip:   tsx0x36e48f8 Timeout timer event
21-03-2017 08:22:36.441 UTC Debug pjsip:   tsx0x36e48f8 State changed from Terminated to Destroyed, event=TIMER
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:213: tsx0x36e48f8 - tu_on_tsx_state UAS, TSX_STATE TIMER state=Destroyed
21-03-2017 08:22:36.441 UTC Debug sproutletproxy.cpp:750: tsx0x36e48f8 - UAS tsx destroyed
21-03-2017 08:22:36.441 UTC Debug sproutletproxy.cpp:1090: Safe for UASTsx to suicide
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:1483: Transaction ((nil)) suiciding
21-03-2017 08:22:36.441 UTC Verbose sproutletproxy.cpp:538: Sproutlet Proxy transaction (0x36e3b40) destroyed
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:494: BasicProxy::UASTsx destructor (0x36e3b40)
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:511: Disconnect UAC transactions from UAS transaction
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:525: Free original request
21-03-2017 08:22:36.441 UTC Debug pjsip:  tdta0x3724020 Destroying txdata Request msg REGISTER/cseq=2 (tdta0x3724020)
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:534: Free un-used best response
21-03-2017 08:22:36.441 UTC Debug pjsip:  tdta0x36dd4f0 Destroying txdata Response msg 408/REGISTER/cseq=2 (tdta0x36dd4f0)
21-03-2017 08:22:36.441 UTC Debug basicproxy.cpp:555: BasicProxy::UASTsx destructor completed
21-03-2017 08:22:36.441 UTC Debug pjsip:  tdta0x3747210 Destroying txdata Response msg 403/REGISTER/cseq=2 (tdta0x3747210)
21-03-2017 08:22:36.441 UTC Debug pjsip:   tsx0x36e48f8 Transaction destroyed!

From Andrew.Edmonds at metaswitch.com  Tue Mar 21 09:12:51 2017
From: Andrew.Edmonds at metaswitch.com (Andrew Edmonds)
Date: Tue, 21 Mar 2017 13:12:51 +0000
Subject: [Project Clearwater] 403 forbidden on registering
In-Reply-To: <db135de9-2355-a2da-1da4-18181445cfb7@4gtss.com>
References: <db135de9-2355-a2da-1da4-18181445cfb7@4gtss.com>
Message-ID: <BLUPR02MB43729812987A98516F53386E53D0@BLUPR02MB437.namprd02.prod.outlook.com>

Hi Ahmed,

Thanks for your question and the logs you have provided. A 403 error typically means that the password Zoiper has provided does not match the password provisioned in Ellis. I've confirmed this is the case by looking at the Sprout logs:

21-03-2017 08:22:36.428 UTC Error authenticationsproutlet.cpp:1168: Authentication failed, Invalid authorization digest (PJSIP_EAUTHINVALIDDIGEST)

Passwords are only shown in Ellis once at the point when you create a subscriber. You can generate a new password for your subscriber by logging into Ellis and pressing the "Reset" button by the subscriber you are trying to register. Once you have done this copy & paste the password shown in Ellis into your Zoiper client making sure not to include any extra spaces.

Can you please try this and let me know if it works.

Thanks,

Andrew

-----Original Message-----
From: Clearwater [mailto:clearwater-bounces at lists.projectclearwater.org] On Behalf Of Ahmed Eldeeb
Sent: Tuesday, March 21, 2017 10:24 AM
To: clearwater at lists.projectclearwater.org
Subject: [Project Clearwater] 403 forbidden on registering

I have a problem while registering using zoiper on my phone i received
403 forbidden from homestead node whenever i try to register however All nodes are running normally The user name is exist at ellis node database and in the homestead_cache tables beside the logs of homestead which shows no errors in the logs, i have attached the logs of homestead and sprout and hope you find a solution.

Thanks in advance.

From Sebastian.Rex at metaswitch.com  Tue Mar 21 13:56:55 2017
From: Sebastian.Rex at metaswitch.com (Sebastian Rex)
Date: Tue, 21 Mar 2017 17:56:55 +0000
Subject: [Project Clearwater] Release note for Boromir
Message-ID: <SN1PR02MB16647461935D32EDDFF8E4F78F3D0@SN1PR02MB1664.namprd02.prod.outlook.com>

The release for Project Clearwater sprint "Boromir" has been cut. The code for this release is tagged as release-119 in GitHub.

This release includes the following bug fixes:


*         bgcf.json and enum.json are inconsistent in whether they allow visual separators in numbers (https://github.com/Metaswitch/sprout/issues/1622)

*         enum.json ordering requirements are unintuitive (https://github.com/Metaswitch/sprout/issues/1619)

*         Config manager doesn't handle certain characters in shared config (https://github.com/Metaswitch/clearwater-etcd/issues/415)

To upgrade to this release, follow the instructions at http://docs.projectclearwater.org/en/stable/Upgrading_a_Clearwater_deployment.html.  If you are deploying an all-in-one node, the standard image (http://vm-images.cw-ngv.com/cw-aio.ova) has been updated for this release.

Seb

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170321/819127bc/attachment.html>

From eleanor at projectclearwater.org  Fri Mar 24 13:50:54 2017
From: eleanor at projectclearwater.org (Eleanor Merry (projectclearwater.org))
Date: Fri, 24 Mar 2017 17:50:54 +0000
Subject: [Project Clearwater] The new project-clearwater-issues repository
Message-ID: <BL2PR02MB20845CA17F999A610CB5BDE09B3E0@BL2PR02MB2084.namprd02.prod.outlook.com>

Hi All,

As we've developed Project Clearwater, we've added a fair number of new GitHub repositories. Each of these repositories had its own issue tracker, with a small number of issues per repo.

However, we've found that this model isn't actually that helpful, as it's really quite hard to work out which repository an issue should be raised against, and there's no inbuilt support in GitHub to easily move an issue from one repository to another. It's also harder to keep track of all the issues across the different repositories.

To simplify this, we've added a new Project-Clearwater-Issues repository - https://github.com/Metaswitch/project-clearwater-issues and migrated community raised issues over to this. We're going to use this going forward to track any issues in Project Clearwater. If you encounter any issues with Project Clearwater, you can either raise them in this repository, or email the mailing list for help.

Ellie

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170324/21fa274f/attachment.html>

From arvindas at hpe.com  Mon Mar 27 04:46:28 2017
From: arvindas at hpe.com (Shirabur, Aravind Ashok (CMS))
Date: Mon, 27 Mar 2017 08:46:28 +0000
Subject: [Project Clearwater] CDIV with MRF Invite message bounce-back to TAS
Message-ID: <TU4PR84MB00647DA578239D9C2ABC65A2DC330@TU4PR84MB0064.NAMPRD84.PROD.OUTLOOK.COM>

Hi,

We are testing the Communication Diversion scenario with MRF announcement, observed that the Announcement INVITE request initiated from the Application Server (TAS) is bouncing back. Do we need to configure the S-CSCF to forward the request to MRF ?

The expected Header in the Announcement INVITE message is missing ? Application server is setting the 'P-Served-User' as "P-Served-User: <sip:7406246264 at mshpe.com>;regstate=reg;sescase=term"


Find the attached wireshark trace for detail ...

[cid:image002.jpg at 01D2A704.B2360C40]



Clearwater-infrastructure version:  1.0-160518.173307

Thanks
Aravind

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170327/089f7000/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.jpg
Type: image/jpeg
Size: 64462 bytes
Desc: image002.jpg
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170327/089f7000/attachment.jpg>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: CDIV_with_mrf_metaswitch.pcapng
Type: application/octet-stream
Size: 34652 bytes
Desc: CDIV_with_mrf_metaswitch.pcapng
URL: <http://lists.projectclearwater.org/pipermail/clearwater_lists.projectclearwater.org/attachments/20170327/089f7000/attachment.obj>

